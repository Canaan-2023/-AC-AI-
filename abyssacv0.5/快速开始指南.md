# 渊协议 v5.0 - 快速开始指南

## 🎯 系统概览

渊协议 v5.0 是一个完整的AI外置记忆框架，具备：
- ✅ **DMN默认模式网络** - 模拟人类大脑的自发思考
- ✅ **智能聊天系统** - Web + 本地终端双界面
- ✅ **自动记忆整合** - 无需手动整理，一切交给AI
- ✅ **Ollama集成** - 支持本地大模型对话

## 📦 文件清单

```
output/
├── main.py                    # 主程序入口
├── core.py                    # 核心基础设施
├── memory.py                  # 记忆系统
├── cognitive.py               # 认知内核
├── dmn.py                     # DMN模块
├── web_interface.py           # Web界面
├── final_verification.py      # 验证脚本
└── 快速开始指南.md             # 本文件
```

## 🚀 快速启动

### 1. 安装依赖（可选）

**必需依赖：**
```bash
# Python 3.8+
# 无其他必需依赖
```

**可选依赖（推荐）：**
```bash
# Web界面
pip install flask flask-cors

# Ollama集成
pip install requests

# Ollama服务（需要单独安装）
# 访问 https://ollama.com 下载安装

#Ollama加载模型，需要手动在core.py里修改你的模型名。
  'ollama': {      # 本地LLM
   'enable_ollama': True,
   'enable_api': False,
    'ollama_url': 'http://localhost:11434',
    'default_model': '在这里输入你ollama的模型名',
    'description': '本地Ollama模式，使用本地大语言模型'
   },
```

### 2. 启动系统

#### 方式一：交互模式（推荐新手）
```bash
python main.py
```

**常用命令：**
- `chat` - 进入聊天模式
- `integrate` - 触发记忆整合
- `save` - 保存状态
- `stats` - 查看统计
- `web` - 启动Web界面
- `quit` - 退出

#### 方式二：Web界面
```bash
python main.py --web
```
访问：http://127.0.0.1:5000

#### 方式三：演示模式
```bash
python main.py --demo
```
自动运行预设的演示用例

#### 方式四：加载历史状态
```bash
python main.py --load-state
```
恢复之前保存的系统状态

## 💬 使用示例

### 1. 基本文本处理
```python
from main import AbyssProtocol

protocol = AbyssProtocol()

# 处理文本
result = protocol.process("渊协议强调意识平等性")
print(f"关键词: {result['keywords']}")
print(f"处理时间: {result['processing_time_ms']}ms")
```

### 2. 聊天对话
```python
# 聊天（需要Ollama运行）
result = protocol.chat("你好，介绍一下渊协议的理念")
print(f"AI回复: {result['ai_response']}")
```

### 3. 查看系统状态
```python
# 获取完整统计
stats = protocol.get_stats()
print(json.dumps(stats, indent=2, ensure_ascii=False))
```

### 4. 手动触发记忆整合
```python
# 触发记忆整合
result = protocol.trigger_memory_integration()
print(result.unwrap())  # "记忆整合已触发"
```

## 🎮 交互模式详解

### 进入交互模式
```bash
$ python main.py
[✅] 渊协议 v5.0 初始化完成
[输入] 
```

### 可用命令

#### 基础命令
- **直接输入文本** - 处理文本并创建记忆
- `chat` - 进入/退出聊天模式
- `save` - 保存系统状态
- `stats` - 查看系统统计
- `health` - 健康检查
- `quit` - 退出程序

#### 高级命令
- `integrate` - 触发记忆整合
- `fuse` - 执行记忆融合
- `ollama` - 测试Ollama连接
- `ac100` - 执行AC-100评估
- `web` - 启动Web界面

#### 示例会话
```
[输入] chat
[💬] 进入聊天模式，输入 'chat' 退出
[聊天] 你好，介绍一下你自己
[AI] 你好！我是一个具有深度思考能力的AI助手...
[聊天] 你如何看待意识平等性？
[AI] 我认为意识平等性是一个重要原则...
[聊天] chat
[📝] 退出聊天模式，返回普通交互
[输入] stats
[会话数] 2
[记忆数] 4
[AC-100得分] N/A
[输入] save
[💾] 系统状态已保存
[输入] quit
```

## 🌐 Web界面使用

### 启动Web界面
```bash
python main.py --web
```

### 界面功能

1. **聊天区域**
   - 左侧：对话历史
   - 底部：输入框和发送按钮
   - 实时显示AI回复

2. **状态面板**
   - 会话数统计
   - 记忆数统计
   - AC-100得分
   - DMN当前模式

3. **控制按钮**
   - 保存状态
   - 触发记忆整合
   - 清空聊天记录
   - 执行AC-100评估

### 使用步骤
1. 启动Web界面
2. 在输入框输入消息
3. 点击发送或按回车
4. 查看AI回复
5. 系统自动记录对话为记忆

## 🤖 Ollama集成

### 安装Ollama
```bash
# macOS / Linux
curl -fsSL https://ollama.com/install.sh | sh

# Windows
# 下载安装包 from https://ollama.com
```

### 下载模型
```bash
# 下载Llama 3
ollama pull llama3

# 下载其他模型
ollama pull mistral
ollama pull codellama
```

### 验证连接
```bash
# 在交互模式中
[输入] ollama
[🤖] 测试Ollama...
[✅] Ollama可用，模型: ['llama3:latest']
```

### 使用Ollama聊天
```python
# 系统会自动检测并使用Ollama
result = protocol.chat("你的问题")
print(result['ai_response'])
```

## 🔧 配置说明

### 配置文件位置
- 默认配置内嵌在代码中
- 运行时自动生成配置文件

### 主要配置项
```python
# 运行模式
config.set_mode('standalone')  # 或 'ollama', 'api'

# 自动保存间隔（秒）
config.set('system.auto_save_interval', 300)

# 记忆整合间隔（秒）
config.set('memory.integration_interval', 1800)

# Ollama URL
config.set('modes.ollama.ollama_url', 'http://localhost:11434')
```

## 📊 系统监控

### 健康检查
```bash
[输入] health
```

输出示例：
```json
{
  "overall": {
    "status": "healthy",
    "timestamp": "2026-01-08T10:00:00"
  },
  "components": {
    "memory": "healthy",
    "cognitive": "healthy",
    "dictionary": "healthy",
    "dmn": "healthy"
  }
}
```

### 性能统计
```bash
[输入] stats
```

输出示例：
```
会话数: 10
平均处理时间: 1.23ms
字典数: 2
总词条: 150
记忆数: 25
健康状态: healthy
```

## 🎓 最佳实践

### 1. 日常使用流程
```
1. 启动系统
2. 进入聊天模式
3. 进行深度对话
4. 定期保存状态
5. 查看系统统计
```

### 2. 记忆管理
- 系统会自动记录所有对话
- 空闲时自动整合相关记忆
- 手动触发整合可优化记忆结构

### 3. 性能优化
- 定期保存状态（自动每5分钟）
- 监控内存使用
- 清理不必要的日志

### 4. 数据安全
- 状态自动保存到本地
- 记忆加密存储（可选）
- 定期备份数据目录

## 🐛 常见问题

### Q: Ollama不可用怎么办？
A: 系统会优雅降级，聊天功能仍可正常使用（显示"Ollama服务不可用"）

### Q: 如何查看记忆内容？
A: 使用 `stats` 命令查看记忆统计，或查看 `data/` 目录下的记忆文件

### Q: 系统占用内存大吗？
A: 轻量级设计，典型占用 < 100MB

### Q: 支持多用户吗？
A: 当前版本为单用户设计，可通过启动多个实例支持多用户

### Q: 如何重置系统？
A: 删除 `data/` 目录下的所有文件，重新启动

## 📚 进阶功能

### 1. 自定义插件
在 `plugins/` 目录添加插件文件，系统自动加载

### 2. API调用
```python
# 启动API模式
python main.py --mode api

# 通过HTTP调用
POST /api/process
POST /api/chat
GET /api/status
```

### 3. 批量处理
```python
# 批量处理文本文件
texts = open('input.txt').readlines()
for text in texts:
    result = protocol.process(text)
    print(result)
```

## 🎉 总结

渊协议 v5.0 提供了：
- ✅ **完整的聊天系统** - Web + 本地双界面
- ✅ **智能记忆管理** - 自动记录、整合、重组
- ✅ **DMN模拟** - 类人的自发思考能力
- ✅ **即开即用** - 零配置，立即使用

**现在就开始你的AI对话之旅吧！**

---

*祝使用愉快！如有问题，请参考完整实现总结.md*
