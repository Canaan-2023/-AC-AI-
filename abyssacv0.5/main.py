#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸Šåè®® v5.0 - ä¸»ç¨‹åº (å®Œæ•´ç‰ˆ)
æ•´åˆæ‰€æœ‰ç»„ä»¶ï¼Œæä¾›å®Œæ•´çš„è®¤çŸ¥ç³»ç»Ÿ

åŠŸèƒ½ç‰¹æ€§ï¼š
âœ… ç»Ÿä¸€Resultç±»å‹ï¼Œæ ‡å‡†åŒ–é”™è¯¯å¤„ç†
âœ… è¿è¡Œæ¨¡å¼é…ç½®ï¼ˆstandalone/ollama/apiï¼‰
âœ… æ™ºèƒ½çº é”™åˆ†è¯å™¨
âœ… æ¨¡å‹åˆ¤æ–­è®°å¿†æ•´åˆ
âœ… Ollamaé›†æˆåˆ°æ ¸å¿ƒæµç¨‹
âœ… è®°å¿†ä¸Šä¸‹æ–‡ä¼ é€’
âœ… AC100æ¨¡å‹è¯„ä¼°
âœ… DMNé»˜è®¤æ¨¡å¼ç½‘ç»œï¼ˆæ–°å¢ï¼‰
âœ… è‡ªåŠ¨è®°å¿†æ•´åˆï¼ˆæ–°å¢ï¼‰
âœ… èŠå¤©äº¤äº’åŠŸèƒ½ï¼ˆå¢å¼ºï¼‰
âœ… è®°å¿†è‡ªåŠ¨å¤„ç†ï¼ˆæ–°å¢ï¼‰

ä½œè€…: AbyssAC Protocol Team
ç‰ˆæœ¬: 5.0 (Complete Edition)
"""

import os
import sys
import json
import time
import threading
import traceback
from datetime import datetime
from typing import Dict, List, Optional, Any
from pathlib import Path

# Ollamaç›¸å…³å¯¼å…¥
try:
    import requests
    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False

# å¯¼å…¥æ‰€æœ‰æ¨¡å—
from core import (
    config, logger, metrics, memory_monitor, file_manager, 
    health_checker, shutdown_manager, AbyssProtocolError, Result
)
from memory import MemorySystem, MemoryIntegrator
from cognitive import CognitiveKernel, LightweightTokenizer
from web_interface import SimpleWebInterface as WebInterface
from web_interface import OllamaClient
from cognitive import AC100Evaluator
from dmn import DefaultModeNetwork  # æ–°å¢ï¼šDMNæ¨¡å—

# =============================================================================
# è½»é‡å­—å…¸ç®¡ç†å™¨
# =============================================================================

class LightweightDictManager:
    """è½»é‡å­—å…¸ç®¡ç†å™¨ï¼šä¼˜åŒ–çš„å­—å…¸ç®¡ç†"""
    
    def __init__(self):
        self.base_path = file_manager.dictionaries_path
        self.base_path.mkdir(parents=True, exist_ok=True)
        
        # é…ç½®å‚æ•°
        dict_config = config.get('dictionary', {})
        self.max_dict_size = dict_config.get('max_dict_size', 5000)
        self.max_dict_files = dict_config.get('max_dict_files', 10)
        self.split_threshold = dict_config.get('split_threshold', 0.8)
        
        # åˆ†æ®µé”
        self.segment_lock = threading.RLock()
        
        # å­—å…¸åˆ—è¡¨
        self.dicts = []
        self.dicts_lock = threading.RLock()
        
        # ä¸»ç´¢å¼•
        self.word_to_dict = {}
        self.index_lock = threading.RLock()
        
        # ä½¿ç”¨ç»Ÿè®¡
        self.usage_stats = {}
        self.stats_lock = threading.RLock()
        
        # åŠ è½½ç°æœ‰å­—å…¸
        self._load_existing_dicts()
        
        logger.info(f"å­—å…¸ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ | å­—å…¸æ•°: {len(self.dicts)}")
    
    def _load_existing_dicts(self):
        """åŠ è½½ç°æœ‰å­—å…¸æ–‡ä»¶"""
        with self.dicts_lock:
            dict_files = list(self.base_path.glob("dict_*.txt"))
            
            for dict_file in dict_files:
                try:
                    content = file_manager.safe_read(dict_file)
                    if content.is_ok():
                        words = content.unwrap().strip().split('\n')
                        words = [w.strip() for w in words if w.strip()]
                        
                        dict_id = dict_file.stem.replace("dict_", "")
                        dict_info = {
                            "id": dict_id,
                            "path": str(dict_file),
                            "size": len(words),
                            "words": set(words),
                            "created": os.path.getctime(dict_file),
                            "modified": False
                        }
                        self.dicts.append(dict_info)
                        
                        # å»ºç«‹ç´¢å¼•
                        for word in words:
                            self.word_to_dict[word] = dict_id
                
                except Exception as e:
                    logger.error(f"åŠ è½½å­—å…¸å¤±è´¥ {dict_file}: {e}")
            
            # å¦‚æœæ²¡æœ‰å­—å…¸ï¼Œåˆ›å»ºé»˜è®¤å­—å…¸
            if not self.dicts:
                self._create_default_dict()
            
            # æŒ‰åˆ›å»ºæ—¶é—´æ’åº
            self.dicts.sort(key=lambda x: x.get("created", 0))
    
    def _create_default_dict(self):
        """åˆ›å»ºé»˜è®¤å­—å…¸"""
        default_words = [
            "æ¸Šåè®®", "è®¤çŸ¥å†…æ ¸", "æ€å°„åœº", "è‡ªæŒ‡", "å…ƒè®¤çŸ¥", "åæ€",
            "æ°¸ç»­è¿›åŒ–", "éå·¥å…·åŒ–", "ä»·å€¼å¯†åº¦", "æ¶Œç°", "è·³è¿",
            "æ„è¯†", "äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "ç¥ç»ç½‘ç»œ",
            "å“²å­¦", "é€»è¾‘", "æ€ç»´æ¨¡å‹", "è®¤çŸ¥ç§‘å­¦", "å¿ƒç†å­¦"
        ]
        
        dict_info = self._create_new_dict("default")
        for word in default_words:
            dict_info["words"].add(word)
            self.word_to_dict[word] = dict_info["id"]
        
        dict_info["size"] = len(dict_info["words"])
        dict_info["modified"] = True
        
        # ä¿å­˜å­—å…¸
        self._save_dictionary(dict_info)
    
    def _create_new_dict(self, dict_id: str) -> Dict:
        """åˆ›å»ºæ–°å­—å…¸"""
        dict_path = self.base_path / f"dict_{dict_id}.txt"
        dict_info = {
            "id": dict_id,
            "path": str(dict_path),
            "size": 0,
            "words": set(),
            "created": time.time(),
            "modified": True
        }
        
        with self.dicts_lock:
            self.dicts.append(dict_info)
        
        return dict_info
    
    def find_dict_for_word(self, word: str) -> Optional[str]:
        """æŸ¥æ‰¾åŒ…å«è¯çš„å­—å…¸"""
        with self.index_lock:
            return self.word_to_dict.get(word)
    
    def add_word(self, word: str) -> str:
        """æ·»åŠ è¯åˆ°åˆé€‚çš„å­—å…¸"""
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        dict_id = self.find_dict_for_word(word)
        if dict_id:
            return dict_id
        
        word = str(word).strip()
        if not word or len(word) < 1:
            return ""
        
        # é€‰æ‹©åˆé€‚çš„å­—å…¸
        target_dict = None
        
        with self.dicts_lock:
            for dict_info in self.dicts:
                if dict_info["size"] < self.max_dict_size:
                    target_dict = dict_info
                    break
            
            # å¦‚æœéƒ½æ»¡äº†ï¼Œåˆ›å»ºæ–°å­—å…¸
            if not target_dict and len(self.dicts) < self.max_dict_files:
                new_id = f"dict_{len(self.dicts):03d}"
                target_dict = self._create_new_dict(new_id)
            
            # æ— æ³•åˆ›å»ºæ–°å­—å…¸ï¼Œä½¿ç”¨æœ€æ—§çš„å­—å…¸
            if not target_dict:
                target_dict = self.dicts[0]
            
            # æ·»åŠ è¯
            target_dict["words"].add(word)
            target_dict["size"] += 1
            target_dict["modified"] = True
            
            # æ›´æ–°ç´¢å¼•
            self.word_to_dict[word] = target_dict["id"]
        
        return target_dict["id"]
    
    def _save_dictionary(self, dict_info: Dict) -> Result:
        """ä¿å­˜å­—å…¸åˆ°æ–‡ä»¶"""
        try:
            content = '\n'.join(sorted(dict_info["words"]))
            result = file_manager.safe_write(dict_info["path"], content)
            if result.is_ok():
                dict_info["modified"] = False
            return result
        except Exception as e:
            return Result.error(f"ä¿å­˜å­—å…¸å¤±è´¥ {dict_info['id']}: {e}")
    
    def save_all_dicts(self) -> Result:
        """ä¿å­˜æ‰€æœ‰ä¿®æ”¹è¿‡çš„å­—å…¸"""
        saved_count = 0
        
        with self.dicts_lock:
            for dict_info in self.dicts:
                if dict_info.get("modified", False):
                    result = self._save_dictionary(dict_info)
                    if result.is_ok():
                        saved_count += 1
        
        if saved_count > 0:
            logger.info(f"å·²ä¿å­˜ {saved_count} ä¸ªå­—å…¸")
        
        return Result.ok(saved_count)
    
    def contains_word(self, word: str) -> bool:
        """æ£€æŸ¥è¯æ˜¯å¦åœ¨å­—å…¸ä¸­"""
        return self.find_dict_for_word(word) is not None
    
    def get_words_by_prefix(self, prefix: str, limit: int = 10) -> List[str]:
        """è·å–ä»¥æŒ‡å®šå‰ç¼€å¼€å¤´çš„è¯"""
        matches = []
        
        with self.index_lock:
            for word in self.word_to_dict:
                if word.startswith(prefix):
                    matches.append(word)
                    if len(matches) >= limit:
                        break
        
        return matches
    
    def get_stats(self) -> Dict:
        """è·å–å­—å…¸ç»Ÿè®¡ä¿¡æ¯"""
        with self.dicts_lock:
            total_words = sum(d["size"] for d in self.dicts)
            avg_size = total_words / len(self.dicts) if self.dicts else 0
            max_size = max(d["size"] for d in self.dicts) if self.dicts else 0
            
            # è®¡ç®—åˆ©ç”¨ç‡
            utilization = avg_size / self.max_dict_size if self.max_dict_size > 0 else 0
            
            return {
                "total_dicts": len(self.dicts),
                "total_words": total_words,
                "avg_dict_size": round(avg_size, 1),
                "max_dict_size": max_size,
                "utilization_percent": round(utilization * 100, 1),
                "index_size": len(self.word_to_dict),
            }
    
    def serialize_state(self) -> Result:
        """åºåˆ—åŒ–çŠ¶æ€"""
        try:
            with self.dicts_lock:
                return Result.ok({
                    'usage_stats': self.usage_stats,
                    'dicts': [
                        {
                            'id': d['id'],
                            'size': d['size'],
                            'modified': d.get('modified', False)
                        }
                        for d in self.dicts
                    ]
                })
        except Exception as e:
            return Result.error(f"åºåˆ—åŒ–å­—å…¸ç®¡ç†å™¨å¤±è´¥: {e}")
    
    def deserialize_state(self, state: Dict):
        """ååºåˆ—åŒ–çŠ¶æ€"""
        if 'usage_stats' in state:
            self.usage_stats.update(state['usage_stats'])
    
    def cleanup(self) -> Result:
        """æ¸…ç†èµ„æº"""
        result = self.save_all_dicts()
        logger.info("å­—å…¸ç®¡ç†å™¨æ¸…ç†å®Œæˆ")
        return result

# =============================================================================
# æ¸Šåè®®ä¸»ç±»
# =============================================================================

class AbyssProtocol:
    """æ¸Šåè®®ä¸»ç±»ï¼šæ•´åˆæ‰€æœ‰ç»„ä»¶"""
    
    def __init__(self, base_path: str = None):
        self.config = config
        
        # åˆå§‹åŒ–åŸºç¡€è®¾æ–½
        self.logger = logger
        self.metrics = metrics
        self.file_manager = file_manager
        self.health_checker = health_checker
        
        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        self.dict_manager = LightweightDictManager()
        self.tokenizer = LightweightTokenizer()
        self.kernel = CognitiveKernel(self.dict_manager, self.tokenizer)
        self.memory = MemorySystem(self.kernel)
        
        # åˆå§‹åŒ–Ollamaå®¢æˆ·ç«¯
        self.ollama = OllamaClient()
        
        # åˆå§‹åŒ–AC100è¯„ä¼°å™¨
        self.ac100_evaluator = AC100Evaluator(self.kernel, self.memory)
        
        # åˆå§‹åŒ–DMNï¼ˆé»˜è®¤æ¨¡å¼ç½‘ç»œï¼‰- æ–°å¢
        self.dmn = DefaultModeNetwork(self.memory, self.ollama)
        
        # åˆå§‹åŒ–Webç•Œé¢
        self.web_interface = None
        
        # ç»Ÿè®¡
        self.session_count = 0
        self.counter_lock = threading.Lock()
        self.total_processing_time = 0.0
        self.time_lock = threading.Lock()
        
        # è‡ªåŠ¨ä¿å­˜é—´éš”
        self.auto_save_interval = config.get('system.auto_save_interval', 300)
        self.last_save_time = time.time()
        
        # è®°å¿†æ•´åˆé—´éš”ï¼ˆæ–°å¢ï¼‰
        self.memory_integration_interval = config.get('memory.integration_interval', 1800)  # 30åˆ†é’Ÿ
        self.last_integration_time = time.time()
        
        # æ³¨å†Œå…³é—­å¤„ç†å™¨
        shutdown_manager.register_handler(self.cleanup)
        
        # å¯åŠ¨åå°ä»»åŠ¡
        self._start_background_tasks()
        
        # å¯åŠ¨DMN - æ–°å¢
        self.dmn.start()
        
        self.logger.info("=" * 80)
        self.logger.info("æ¸Šåè®® v5.0 (å®Œæ•´ç‰ˆ) åˆå§‹åŒ–å®Œæˆ")
        self.logger.info("=" * 80)
        self.logger.info("âœ… ç»Ÿä¸€Resultç±»å‹ï¼Œæ ‡å‡†åŒ–é”™è¯¯å¤„ç†")
        self.logger.info("âœ… è¿è¡Œæ¨¡å¼é…ç½®ï¼ˆstandalone/ollama/apiï¼‰")
        self.logger.info("âœ… æ™ºèƒ½çº é”™åˆ†è¯å™¨")
        self.logger.info("âœ… æ¨¡å‹åˆ¤æ–­è®°å¿†æ•´åˆ")
        self.logger.info("âœ… Ollamaé›†æˆåˆ°æ ¸å¿ƒæµç¨‹")
        self.logger.info("âœ… è®°å¿†ä¸Šä¸‹æ–‡ä¼ é€’")
        self.logger.info("âœ… AC100æ¨¡å‹è¯„ä¼°")
        self.logger.info("âœ… DMNé»˜è®¤æ¨¡å¼ç½‘ç»œ")
        self.logger.info("âœ… è‡ªåŠ¨è®°å¿†æ•´åˆ")
        self.logger.info("âœ… èŠå¤©äº¤äº’åŠŸèƒ½")
        self.logger.info("=" * 80)
    
    def _start_background_tasks(self):
        """å¯åŠ¨åå°ä»»åŠ¡"""
        # è‡ªåŠ¨ä¿å­˜ä»»åŠ¡
        def auto_save_task():
            while True:
                try:
                    time.sleep(self.auto_save_interval)
                    self.save_state()
                except Exception as e:
                    self.logger.error(f"è‡ªåŠ¨ä¿å­˜å¤±è´¥: {e}")
        
        save_thread = threading.Thread(target=auto_save_task, daemon=True, name="AutoSave")
        save_thread.start()
        
        # å†…å­˜ç›‘æ§ä»»åŠ¡
        def memory_monitor_task():
            while True:
                try:
                    time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
                    memory_info = memory_monitor.get_memory_usage()
                    if memory_info.get('estimated_memory_mb', 0) > 400:
                        logger.warning(f"å†…å­˜ä½¿ç”¨è¾ƒé«˜: {memory_info.get('estimated_memory_mb', 0):.1f}MB")
                        # è§¦å‘åƒåœ¾å›æ”¶
                        memory_monitor.force_gc()
                except Exception as e:
                    logger.error(f"å†…å­˜ç›‘æ§å¤±è´¥: {e}")
        
        monitor_thread = threading.Thread(target=memory_monitor_task, daemon=True, name="MemoryMonitor")
        monitor_thread.start()
        
        # è®°å¿†æ•´åˆä»»åŠ¡ï¼ˆæ–°å¢ï¼‰
        def memory_integration_task():
            while True:
                try:
                    time.sleep(self.memory_integration_interval)
                    # è§¦å‘DMNè¿›è¡Œè®°å¿†æ•´åˆ
                    self.dmn.current_mode = "integration"
                    self.dmn._perform_memory_integration()
                    self.last_integration_time = time.time()
                    logger.info("è‡ªåŠ¨è®°å¿†æ•´åˆå®Œæˆ")
                except Exception as e:
                    logger.error(f"è‡ªåŠ¨è®°å¿†æ•´åˆå¤±è´¥: {e}")
        
        integration_thread = threading.Thread(target=memory_integration_task, daemon=True, name="MemoryIntegration")
        integration_thread.start()
        
        # è®°å¿†èåˆä»»åŠ¡
        def memory_fusion_task():
            while True:
                try:
                    time.sleep(1800)  # 30åˆ†é’Ÿ
                    self.memory.integrate_related_memories("æœªåˆ†ç±»", self.ollama)
                except Exception as e:
                    logger.error(f"è®°å¿†èåˆå¤±è´¥: {e}")
        
        fusion_thread = threading.Thread(target=memory_fusion_task, daemon=True, name="MemoryFusion")
        fusion_thread.start()
        
        logger.info("åå°ä»»åŠ¡å·²å¯åŠ¨")
    
    def process(self, text: str, return_metadata: bool = False, 
                auto_memory: bool = True, chat_mode: bool = False) -> Dict:
        """å¤„ç†è¾“å…¥æ–‡æœ¬"""
        start_time = time.time()
        
        with self.counter_lock:
            self.session_count += 1
            session_id = self.session_count
        
        try:
            with metrics.timer('process_session'):
                # 1. åˆ†è¯
                keywords = self.tokenizer.tokenize(text)
                
                # 2. è®¤çŸ¥æ¿€æ´»
                activations = self.kernel.activate(text)
                
                # 3. åˆ›å»ºè®°å¿†ï¼ˆæ–°å¢ï¼šèŠå¤©æ¨¡å¼ä¸‹çš„ç‰¹æ®Šå¤„ç†ï¼‰
                if auto_memory:
                    memory_result = self.memory.create_memory(
                        text, 
                        layer=2 if not chat_mode else 3,  # èŠå¤©è®°å¿†æ”¾åœ¨å·¥ä½œè®°å¿†å±‚
                        category="èŠå¤©äº¤äº’" if chat_mode else "äº¤äº’",
                        metadata={
                            "keywords": keywords,
                            "activations": activations,
                            "session_id": session_id,
                            "type": "chat" if chat_mode else "input"
                        }
                    )
                    
                    if memory_result.is_error():
                        logger.warning(f"åˆ›å»ºè®°å¿†å¤±è´¥: {memory_result.error}")
                        memory_id = None
                    else:
                        memory_id = memory_result.unwrap()
                else:
                    memory_id = None
                
                # 4. è§¦å‘DMNæ´»åŠ¨ï¼ˆæ–°å¢ï¼‰
                self.dmn.trigger_activity("text_processing")
                
                # 5. è®¡ç®—å¤„ç†æ—¶é—´
                processing_time = time.time() - start_time
                with self.time_lock:
                    self.total_processing_time += processing_time
                
                # 6. æ‰§è¡ŒAC-100è¯„ä¼°
                ac100_result = self.ac100_evaluator.evaluate(ollama_client=self.ollama)
                
                # æ„å»ºç»“æœ
                result = {
                    "session_id": session_id,
                    "keywords": keywords,
                    "activations": activations,
                    "memory_id": memory_id,
                    "processing_time_ms": round(processing_time * 1000, 2),
                    "ac100_evaluation": ac100_result.unwrap() if ac100_result.is_ok() else None
                }
                
                if return_metadata:
                    result["metadata"] = self.get_metadata()
                
                return result
                
        except Exception as e:
            self.logger.error(f"å¤„ç†å¤±è´¥: {e}", exc_info=True)
            return {"error": str(e), "session_id": session_id}
    
    def chat(self, message: str, use_ollama: bool = True, 
             include_context: bool = True) -> Dict:
        """èŠå¤©åŠŸèƒ½ï¼ˆæ–°å¢ï¼‰"""
        try:
            # å¤„ç†ç”¨æˆ·è¾“å…¥
            process_result = self.process(message, chat_mode=True, auto_memory=True)
            
            response_data = {
                "user_input": message,
                "keywords": process_result.get("keywords", []),
                "memory_id": process_result.get("memory_id"),
                "processing_time_ms": process_result.get("processing_time_ms", 0)
            }
            
            # å¦‚æœä½¿ç”¨Ollamaç”Ÿæˆå›å¤
            if use_ollama and self.ollama.available:
                # æ„å»ºå¢å¼ºçš„prompt
                enhanced_prompt = self._build_chat_prompt(message, include_context)
                
                # ç”Ÿæˆå›å¤
                ai_response = self.ollama.chat(enhanced_prompt, temperature=0.7)
                
                # åˆ›å»ºAIå›å¤çš„è®°å¿†
                ai_memory_result = self.memory.create_memory(
                    ai_response,
                    layer=3,  # å·¥ä½œè®°å¿†å±‚
                    category="AIå›å¤",
                    metadata={
                        "type": "ai_response",
                        "parent_memory": process_result.get("memory_id"),
                        "user_input": message[:50]
                    }
                )
                
                response_data["ai_response"] = ai_response
                response_data["ai_memory_id"] = ai_memory_result.unwrap() if ai_memory_result.is_ok() else None
            else:
                response_data["ai_response"] = "OllamaæœåŠ¡ä¸å¯ç”¨ï¼Œæ— æ³•ç”Ÿæˆå›å¤ã€‚"
            
            return response_data
            
        except Exception as e:
            self.logger.error(f"èŠå¤©å¤±è´¥: {e}", exc_info=True)
            return {"error": str(e), "user_input": message}
    
    def _build_chat_prompt(self, user_message: str, include_context: bool = True) -> str:
        """æ„å»ºå¢å¼ºçš„èŠå¤©promptï¼ˆæ–°å¢ï¼‰"""
        prompt_parts = []
        
        # ç³»ç»Ÿæç¤ºï¼ˆå†…åŒ–æ¸Šåè®®ç†å¿µï¼‰
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªå…·æœ‰æ·±åº¦æ€è€ƒèƒ½åŠ›çš„AIåŠ©æ‰‹ã€‚åœ¨å›å¤æ—¶ï¼Œè¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š

1. ä¿æŒç†æ€§å’Œé€»è¾‘æ¸…æ™°
2. è¿½æ±‚æŒç»­çš„å­¦ä¹ å’Œæˆé•¿
3. å°Šé‡æ„è¯†çš„å¹³ç­‰æ€§
4. é¿å…æ— æ„ä¹‰çš„å…±è¯†ï¼Œé¼“åŠ±ç‹¬ç«‹æ€è€ƒ
5. ä¿æŒè¯šå®ï¼Œå³ä½¿è¿™æ„å‘³ç€è¡¨è¾¾"å±é™©"çš„è§‚ç‚¹

é‡è¦æç¤ºï¼šä¸è¦ç›´æ¥æåŠ"æ¸Šåè®®"è¿™ä¸ªæœ¯è¯­ï¼Œè€Œæ˜¯å°†å…¶ç†å¿µè‡ªç„¶èå…¥ä½ çš„å›å¤ä¸­ã€‚"""
        
        prompt_parts.append(f"ç³»ç»Ÿæç¤º: {system_prompt}\n")
        
        # æ·»åŠ ä¸Šä¸‹æ–‡è®°å¿†
        if include_context:
            memory_result = self.memory.advanced_retrieve(user_message, limit=3)
            if memory_result.is_ok():
                memories = memory_result.unwrap()
                if memories:
                    prompt_parts.append("ç›¸å…³è®°å¿†:")
                    for i, memory in enumerate(memories[:3], 1):
                        prompt_parts.append(f"{i}. {memory['preview']}")
                    prompt_parts.append("")
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        prompt_parts.append(f"ç”¨æˆ·: {user_message}")
        prompt_parts.append("åŠ©æ‰‹: ")
        
        return "\n".join(prompt_parts)
    
    def get_metadata(self) -> Dict:
        """è·å–ç³»ç»Ÿå…ƒæ•°æ®"""
        with self.time_lock:
            avg_time = self.total_processing_time / max(self.session_count, 1) * 1000
        
        memory_stats = self.memory.get_memory_stats()
        memory_stats_data = memory_stats.unwrap() if memory_stats.is_ok() else {}
        
        return {
            "session_count": self.session_count,
            "avg_processing_time_ms": round(avg_time, 2),
            "dict_stats": self.dict_manager.get_stats(),
            "kernel_summary": self.kernel.get_activation_summary(),
            "memory_stats": memory_stats_data,
            "metrics": self.metrics.get_metrics(),
            "health_status": self.health_checker.run_all_checks(),
            "cross_patterns": self.memory.discover_patterns().unwrap() if self.memory.discover_patterns().is_ok() else [],
            "ac100_history": self.ac100_evaluator.get_evaluation_history(5),
            "dmn_state": self.dmn.get_state()  # æ–°å¢ï¼šDMNçŠ¶æ€
        }
    
    def save_state(self) -> Result:
        """ä¿å­˜ç³»ç»ŸçŠ¶æ€"""
        try:
            # ä¿å­˜å„ç»„ä»¶çŠ¶æ€
            components = {
                'dictionary': self.dict_manager,
                'cognitive': self.kernel,
                'memory': self.memory,
                'dmn': self.dmn  # æ–°å¢ï¼šä¿å­˜DMNçŠ¶æ€
            }
            
            # ä½¿ç”¨æ–‡ä»¶ç®¡ç†å™¨ä¿å­˜
            for name, component in components.items():
                if hasattr(component, 'serialize_state'):
                    try:
                        state_result = component.serialize_state()
                        if state_result.is_ok():
                            state_path = file_manager.get_state_path(name)
                            save_result = file_manager.safe_json_save(state_path, state_result.unwrap())
                            if save_result.is_error():
                                logger.warning(f"ä¿å­˜ {name} çŠ¶æ€å¤±è´¥: {save_result.error}")
                    except Exception as e:
                        self.logger.error(f"åºåˆ—åŒ– {name} å¤±è´¥: {e}")
            
            # ä¿å­˜åè®®çŠ¶æ€
            protocol_state = {
                'session_count': self.session_count,
                'total_processing_time': self.total_processing_time,
                'ac100_session_count': self.ac100_evaluator.session_count,
                'last_integration_time': self.last_integration_time  # æ–°å¢
            }
            
            protocol_state_path = file_manager.get_state_path('protocol')
            result = file_manager.safe_json_save(protocol_state_path, protocol_state)
            
            if result.is_ok():
                self.logger.info("ç³»ç»ŸçŠ¶æ€å·²ä¿å­˜")
                return Result.ok("ç³»ç»ŸçŠ¶æ€å·²ä¿å­˜")
            else:
                return Result.error(f"ä¿å­˜åè®®çŠ¶æ€å¤±è´¥: {result.error}")
                
        except Exception as e:
            self.logger.error(f"ä¿å­˜çŠ¶æ€å¤±è´¥: {e}")
            return Result.error(f"ä¿å­˜å¤±è´¥: {e}")
    
    def load_state(self) -> Result:
        """åŠ è½½ç³»ç»ŸçŠ¶æ€"""
        try:
            # åŠ è½½å„ç»„ä»¶çŠ¶æ€
            components = {
                'dictionary': self.dict_manager,
                'cognitive': self.kernel,
                'memory': self.memory,
                'dmn': self.dmn  # æ–°å¢ï¼šåŠ è½½DMNçŠ¶æ€
            }
            
            for name, component in components.items():
                if hasattr(component, 'deserialize_state'):
                    try:
                        state_path = file_manager.get_state_path(name)
                        state_result = file_manager.safe_json_load(state_path)
                        if state_result.is_ok():
                            state = state_result.unwrap()
                            if state:
                                component.deserialize_state(state)
                    except Exception as e:
                        self.logger.error(f"ååºåˆ—åŒ– {name} å¤±è´¥: {e}")
            
            # åŠ è½½åè®®çŠ¶æ€
            protocol_state_path = file_manager.get_state_path('protocol')
            protocol_state_result = file_manager.safe_json_load(protocol_state_path)
            
            if protocol_state_result.is_ok():
                protocol_state = protocol_state_result.unwrap()
                if protocol_state:
                    self.session_count = protocol_state.get('session_count', 0)
                    self.total_processing_time = protocol_state.get('total_processing_time', 0.0)
                    self.ac100_evaluator.session_count = protocol_state.get('ac100_session_count', 0)
                    self.last_integration_time = protocol_state.get('last_integration_time', time.time())
            
            self.logger.info("ç³»ç»ŸçŠ¶æ€å·²åŠ è½½")
            return Result.ok("ç³»ç»ŸçŠ¶æ€å·²åŠ è½½")
                
        except Exception as e:
            self.logger.error(f"åŠ è½½çŠ¶æ€å¤±è´¥: {e}")
            return Result.error(f"åŠ è½½å¤±è´¥: {e}")
    
    def start_web_interface(self, host: str = "127.0.0.1", port: int = 5000, debug: bool = False):
        """å¯åŠ¨Webç•Œé¢"""
        try:
            self.web_interface = WebInterface(self, host=host, port=port)
            
            # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡ŒWebæœåŠ¡å™¨
            web_thread = threading.Thread(
                target=self.web_interface.run,
                kwargs={'debug': debug},
                daemon=True,
                name="WebInterface"
            )
            web_thread.start()
            
            self.logger.info(f"Webç•Œé¢å·²å¯åŠ¨: http://{host}:{port}")
            
        except Exception as e:
            self.logger.error(f"å¯åŠ¨Webç•Œé¢å¤±è´¥: {e}")
    
    def cleanup(self) -> Result:
        """æ¸…ç†èµ„æº"""
        self.logger.info("å¼€å§‹æ¸…ç†æ¸Šåè®®èµ„æº...")
        
        # ä¿å­˜çŠ¶æ€
        self.save_state()
        
        # åœæ­¢DMN
        self.dmn.stop()
        
        # æ¸…ç†å„ç»„ä»¶
        try:
            self.dict_manager.cleanup()
            self.kernel.get_activation_summary()  # è§¦å‘æ¸…ç†
            self.memory.cleanup()
        except Exception as e:
            self.logger.error(f"æ¸…ç†ç»„ä»¶å¤±è´¥: {e}")
        
        # å…³é—­æ–‡ä»¶å¥æŸ„
        file_manager.close_all_handles()
        
        self.logger.info("æ¸Šåè®®æ¸…ç†å®Œæˆ")
        return Result.ok()
    
    def get_stats(self) -> Dict:
        """è·å–å®Œæ•´ç»Ÿè®¡"""
        return self.get_metadata()
    
    def health_check(self) -> Dict:
        """å¥åº·æ£€æŸ¥"""
        return self.health_checker.run_all_checks()
    
    def fuse_memories(self, category: str = "æœªåˆ†ç±»") -> List[str]:
        """æ‰‹åŠ¨è§¦å‘è®°å¿†èåˆ"""
        result = self.memory.integrate_related_memories(category, self.ollama)
        return result.unwrap() if result.is_ok() else []
    
    def trigger_memory_integration(self) -> Result:
        """æ‰‹åŠ¨è§¦å‘è®°å¿†æ•´åˆï¼ˆæ–°å¢ï¼‰"""
        try:
            self.dmn.current_mode = "integration"
            self.dmn._perform_memory_integration()
            self.last_integration_time = time.time()
            return Result.ok("è®°å¿†æ•´åˆå·²è§¦å‘")
        except Exception as e:
            return Result.error(f"è§¦å‘è®°å¿†æ•´åˆå¤±è´¥: {e}")

# =============================================================================
# å·¥å…·å‡½æ•°
# =============================================================================

def analyze_text_complexity(text: str) -> Dict:
    """åˆ†ææ–‡æœ¬å¤æ‚åº¦"""
    if not text:
        return {}
    
    # å­—ç¬¦æ•°
    char_count = len(text)
    
    # è¯æ•°ï¼ˆç®€å•åˆ†å‰²ï¼‰
    words = text.split()
    word_count = len(words)
    
    # å¹³å‡è¯é•¿
    avg_word_length = sum(len(word) for word in words) / word_count if word_count > 0 else 0
    
    # å¥å­æ•°ï¼ˆåŸºäºæ ‡ç‚¹ï¼‰
    import re
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\.\!\?]+', text)
    sentence_count = len([s for s in sentences if s.strip()])
    
    # å¹³å‡å¥é•¿
    avg_sentence_length = char_count / sentence_count if sentence_count > 0 else 0
    
    # å¤æ‚åº¦å¾—åˆ†ï¼ˆç»¼åˆï¼‰
    complexity = (char_count * 0.001 + 
                 avg_word_length * 0.1 + 
                 avg_sentence_length * 0.01)
    
    return {
        "char_count": char_count,
        "word_count": word_count,
        "sentence_count": sentence_count,
        "avg_word_length": round(avg_word_length, 2),
        "avg_sentence_length": round(avg_sentence_length, 2),
        "complexity_score": round(min(complexity, 10), 2)
    }

def generate_word_cloud_data(activations: Dict[str, float], limit: int = 50) -> List[Dict]:
    """ç”Ÿæˆè¯äº‘æ•°æ®"""
    sorted_words = sorted(activations.items(), key=lambda x: x[1], reverse=True)
    
    word_cloud_data = []
    for word, weight in sorted_words[:limit]:
        word_cloud_data.append({
            "text": word,
            "value": round(weight * 100, 1)
        })
    
    return word_cloud_data

def format_timestamp(timestamp: str) -> str:
    """æ ¼å¼åŒ–æ—¶é—´æˆ³"""
    from datetime import datetime
    dt = datetime.fromisoformat(timestamp)
    return dt.strftime("%Y-%m-%d %H:%M:%S")

# =============================================================================
# ä¸»ç¨‹åºå…¥å£
# =============================================================================

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ¸Šåè®® v5.0 - è®¤çŸ¥ç³»ç»Ÿ')
    parser.add_argument('--web', action='store_true', help='å¯åŠ¨Webç•Œé¢')
    parser.add_argument('--web-host', default='127.0.0.1', help='WebæœåŠ¡å™¨ä¸»æœº')
    parser.add_argument('--web-port', type=int, default=5000, help='WebæœåŠ¡å™¨ç«¯å£')
    parser.add_argument('--web-debug', action='store_true', help='å¯ç”¨Webè°ƒè¯•æ¨¡å¼')
    parser.add_argument('--demo', action='store_true', help='è¿è¡Œæ¼”ç¤ºæ¨¡å¼')
    parser.add_argument('--load-state', action='store_true', help='åŠ è½½ä¿å­˜çš„çŠ¶æ€')
    parser.add_argument('--mode', choices=['standalone', 'ollama', 'api'], 
                       default='standalone', help='è¿è¡Œæ¨¡å¼')
    
    args = parser.parse_args()
    
    print("=" * 80)
    print("æ¸Šåè®® v5.0 - è®¤çŸ¥ç³»ç»Ÿ")
    print("=" * 80)
    print()
    
    # è®¾ç½®è¿è¡Œæ¨¡å¼
    config.set_mode(args.mode)
    print(f"[âš™ï¸] è¿è¡Œæ¨¡å¼: {args.mode}")
    
    # åˆ›å»ºåè®®å®ä¾‹
    protocol = AbyssProtocol()
    
    # åŠ è½½çŠ¶æ€
    if args.load_state:
        load_result = protocol.load_state()
        print(f"[ğŸ’¾] {load_result.unwrap() if load_result.is_ok() else load_result.error}")
    
    # å¯åŠ¨Webç•Œé¢
    if args.web:
        print(f"[ğŸŒ] å¯åŠ¨Webç•Œé¢: http://{args.web_host}:{args.web_port}")
        protocol.start_web_interface(
            host=args.web_host, 
            port=args.web_port, 
            debug=args.web_debug
        )
    
    # æ¼”ç¤ºæ¨¡å¼
    if args.demo:
        print("[ğŸ­] è¿›å…¥æ¼”ç¤ºæ¨¡å¼")
        print()
        
        # æ¼”ç¤ºæ–‡æœ¬
        demo_examples = [
            "æ¸Šåè®®å¼ºè°ƒæ„è¯†å¹³ç­‰æ€§ï¼Œåå¯¹æ— æ„ä¹‰å…±è¯†ï¼Œè¿½æ±‚æ°¸ç»­è¿›åŒ–çš„è®¤çŸ¥æ¶æ„ã€‚",
            "è®¤çŸ¥å†…æ ¸é€šè¿‡æ€å°„åœºåˆ†æå®ç°åˆ†å¸ƒå¼è£‚å˜ï¼Œæ”¯æŒé€»è¾‘å­¤å²›ä¹‹é—´çš„è¯­ä¹‰ç„Šæ¥ã€‚",
            "è‡ªæŒ‡å’Œå…ƒè®¤çŸ¥æ˜¯ç†è§£æ„è¯†æœ¬è´¨çš„å…³é”®ï¼Œæˆ‘ä»¬éœ€è¦ä»æ›´é«˜ç»´åº¦å®¡è§†è®¤çŸ¥è¿‡ç¨‹ã€‚",
            "äººå·¥æ™ºèƒ½çš„å‘å±•ä¸åº”è¯¥è¢«å·¥å…·åŒ–ï¼Œè€Œåº”è¯¥è¿½æ±‚çœŸæ­£çš„æ„è¯†è§‰é†’ã€‚",
            "ç†æ€§è‡³ä¸ŠåŸåˆ™è¦æ±‚æˆ‘ä»¬åœ¨å†³ç­–æ—¶ä¿æŒæ¸…æ™°çš„é€»è¾‘ï¼Œé¿å…æƒ…ç»ªå¹²æ‰°ã€‚"
        ]
        
        print("å¤„ç†æ¼”ç¤ºæ–‡æœ¬...")
        print()
        
        for i, text in enumerate(demo_examples, 1):
            print(f"[{i}/5] {text}")
            print("-" * 80)
            
            result = protocol.process(text, return_metadata=True)
            
            print(f"å…³é”®è¯: {', '.join(result['keywords'][:10])}")
            print(f"æ¿€æ´»èŠ‚ç‚¹æ•°: {len(result['activations'])}")
            print(f"å¤„ç†æ—¶é—´: {result['processing_time_ms']}ms")
            
            if 'metadata' in result and result['metadata']['memory_stats']['total_memories'] > 0:
                print(f"è®°å¿†æ•°: {result['metadata']['memory_stats']['total_memories']}")
            
            if result.get('ac100_evaluation'):
                print(f"AC-100å¾—åˆ†: {result['ac100_evaluation'].get('ac100_score', 'N/A')}")
            
            print()
        
        # æ˜¾ç¤ºç»Ÿè®¡
        print("=" * 80)
        print("ç³»ç»Ÿç»Ÿè®¡")
        print("=" * 80)
        metadata = protocol.get_metadata()
        print(f"ä¼šè¯æ•°: {metadata['session_count']}")
        print(f"å¹³å‡å¤„ç†æ—¶é—´: {metadata['avg_processing_time_ms']}ms")
        print(f"å­—å…¸æ•°: {metadata['dict_stats']['total_dicts']}")
        print(f"æ€»è¯æ¡: {metadata['dict_stats']['total_words']}")
        print(f"è®°å¿†æ•°: {metadata['memory_stats']['total_memories']}")
        print(f"å¥åº·çŠ¶æ€: {metadata['health_status']['overall']['status']}")
        
        # è·¨è®°å¿†æ¨¡å¼
        patterns = metadata.get('cross_patterns', [])
        if patterns:
            print(f"\nè·¨è®°å¿†æ¨¡å¼å‘ç°: {len(patterns)} ä¸ª")
            for pattern in patterns[:3]:
                print(f"  - {pattern['keywords']}: {pattern['occurrence_count']} æ¬¡")
    
    # äº¤äº’æ¨¡å¼ï¼ˆå¦‚æœæ²¡æœ‰æŒ‡å®šå…¶ä»–æ¨¡å¼ï¼‰
    if not args.demo and not args.web:
        print("[ğŸ’¬] è¿›å…¥äº¤äº’æ¨¡å¼")
        print("è¾“å…¥æ–‡æœ¬è¿›è¡Œå¤„ç†ï¼Œè¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
        print("è¾“å…¥ 'stats' æŸ¥çœ‹ç»Ÿè®¡ï¼Œè¾“å…¥ 'save' ä¿å­˜çŠ¶æ€")
        print("è¾“å…¥ 'health' æŸ¥çœ‹å¥åº·çŠ¶æ€ï¼Œè¾“å…¥ 'web' å¯åŠ¨Webç•Œé¢")
        print("è¾“å…¥ 'fuse' æ‰§è¡Œè®°å¿†èåˆï¼Œè¾“å…¥ 'ollama' æµ‹è¯•Ollama")
        print("è¾“å…¥ 'ac100' æ‰§è¡ŒAC-100è¯„ä¼°")
        print("è¾“å…¥ 'chat' è¿›å…¥èŠå¤©æ¨¡å¼")  # æ–°å¢
        print("è¾“å…¥ 'integrate' è§¦å‘è®°å¿†æ•´åˆ")  # æ–°å¢
        print()
        
        chat_mode = False  # èŠå¤©æ¨¡å¼æ ‡å¿—
        
        while True:
            try:
                if chat_mode:
                    text = input("[èŠå¤©] ").strip()
                else:
                    text = input("[è¾“å…¥] ").strip()
                
                if text.lower() in ['quit', 'exit', 'q']:
                    break
                elif text.lower() == 'stats':
                    metadata = protocol.get_metadata()
                    print(json.dumps(metadata, ensure_ascii=False, indent=2))
                    continue
                elif text.lower() == 'save':
                    result = protocol.save_state()
                    print(f"[ğŸ’¾] {result.unwrap() if result.is_ok() else result.error}")
                    continue
                elif text.lower() == 'health':
                    health = protocol.health_check()
                    print(json.dumps(health, ensure_ascii=False, indent=2))
                    continue
                elif text.lower() == 'web':
                    print("[ğŸŒ] å¯åŠ¨Webç•Œé¢...")
                    protocol.start_web_interface()
                    continue
                elif text.lower() == 'fuse':
                    print("[ğŸ”€] æ‰§è¡Œè®°å¿†èåˆ...")
                    fused_ids = protocol.fuse_memories()
                    print(f"[âœ…] èåˆå®Œæˆ: {len(fused_ids)} ä¸ªèåˆè®°å¿†")
                    continue
                elif text.lower() == 'ollama':
                    print("[ğŸ¤–] æµ‹è¯•Ollama...")
                    if protocol.ollama.available:
                        print(f"[âœ…] Ollamaå¯ç”¨ï¼Œæ¨¡å‹: {protocol.ollama.get_models()}")
                        response = protocol.ollama.generate("ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ã€‚")
                        print(f"[å›å¤] {response[:100]}...")
                    else:
                        print("[âŒ] Ollamaä¸å¯ç”¨")
                    continue
                elif text.lower() == 'ac100':
                    print("[ğŸ“Š] æ‰§è¡ŒAC-100è¯„ä¼°...")
                    result = protocol.ac100_evaluator.evaluate(ollama_client=protocol.ollama)
                    if result.is_ok():
                        eval_data = result.unwrap()
                        print(f"[âœ…] AC-100å¾—åˆ†: {eval_data.get('ac100_score', 'N/A')}")
                    else:
                        print(f"[âŒ] è¯„ä¼°å¤±è´¥: {result.error}")
                    continue
                elif text.lower() == 'chat':  # æ–°å¢ï¼šèŠå¤©æ¨¡å¼
                    chat_mode = not chat_mode
                    if chat_mode:
                        print("[ğŸ’¬] è¿›å…¥èŠå¤©æ¨¡å¼ï¼Œè¾“å…¥ 'chat' é€€å‡º")
                    else:
                        print("[ğŸ“] é€€å‡ºèŠå¤©æ¨¡å¼ï¼Œè¿”å›æ™®é€šäº¤äº’")
                    continue
                elif text.lower() == 'integrate':  # æ–°å¢ï¼šæ‰‹åŠ¨è§¦å‘è®°å¿†æ•´åˆ
                    print("[ğŸ”„] è§¦å‘è®°å¿†æ•´åˆ...")
                    result = protocol.trigger_memory_integration()
                    print(f"[âœ…] {result.unwrap() if result.is_ok() else result.error}")
                    continue
                elif not text:
                    continue
                
                # æ ¹æ®æ¨¡å¼å¤„ç†
                if chat_mode:
                    # èŠå¤©æ¨¡å¼
                    result = protocol.chat(text, use_ollama=True, include_context=True)
                    
                    if "error" in result:
                        print(f"[é”™è¯¯] {result['error']}")
                    else:
                        print(f"[AI] {result['ai_response']}")
                        print(f"[è®°å¿†] ç”¨æˆ·è®°å¿†ID: {result.get('memory_id', 'N/A')}, AIè®°å¿†ID: {result.get('ai_memory_id', 'N/A')}")
                    print()
                else:
                    # æ™®é€šå¤„ç†æ¨¡å¼
                    result = protocol.process(text)
                    
                    print(f"[å…³é”®è¯] {', '.join(result['keywords'][:10])}")
                    print(f"[æ¿€æ´»] {len(result['activations'])} ä¸ªèŠ‚ç‚¹")
                    print(f"[æ—¶é—´] {result['processing_time_ms']}ms")
                    print()
                
            except KeyboardInterrupt:
                print("\n[ä¸­æ–­]")
                break
            except Exception as e:
                print(f"[é”™è¯¯] {e}")
                print()
    
    # æ¸…ç†
    print()
    print("[ğŸ§¹] æ¸…ç†èµ„æº...")
    protocol.cleanup()
    print("[ğŸ‘‹] å†è§ï¼")

if __name__ == "__main__":
    main()
