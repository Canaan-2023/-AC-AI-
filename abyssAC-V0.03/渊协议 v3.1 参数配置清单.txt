# 渊协议 v3.1 参数配置清单  
（全部在 `abyss_protocol.py` 头部）

---

## 一、AI 接口配置
| 参数名 | 所在行区域 | 作用 | 可选值 | 修改示例 |
|--------|------------|------|--------|----------|
| `model_type` | `AI_INTERFACE_CONFIG` | 选择后端模型 | `"local"` / `"ollama"` / `"openai"` | `"model_type": "ollama"` |
| `timeout_seconds` | 同上 | 单次模型调用超时 | 整数（秒） | `30` |
| `max_tokens` | 同上 | 最大返回 token 数 | 整数 | `1000` |
| `temperature` | 同上 | 采样温度 | 0.0–2.0 | `0.7` |

**接入模型步骤**  
1. 改 `model_type` 为 `"ollama"` 或 `"openai"`  
2. 同步修改 `ExtendedAIInterface.call_ai_model()` 内对应分支（已有模板，填 API-Key 或本地地址即可）

---

## 二、认知内核运行阈值
| 参数名 | 所在行区域 | 作用 | 缺省值 | 安全范围 | 修改示例 |
|--------|------------|------|--------|----------|----------|
| `top_k_nodes` | `COGNITIVE_KERNEL_CONFIG` | 内核保存高频节点数 | 500 | 100–2000 | `500` |
| `high_score_threshold` | 同上 | AC-100 高分线（0–1） | 0.8 | 0.6–0.95 | `0.85` |
| `low_score_threshold` | 同上 | AC-100 低分线 | 0.5 | 0.3–0.7 | `0.45` |
| `evolving_threshold` | 同上 | 进入 EVOLVING 状态 | 0.6 | 0.5–0.9 | `0.65` |
| `min_activated_nodes` | 同上 | 最少激活节点才更新态射 | 3 | 2–10 | `5` |

---

## 三、记忆系统容量
| 参数名 | 所在行区域 | 作用 | 缺省值 | 安全范围 | 修改示例 |
|--------|------------|------|--------|----------|----------|
| `MAX_DICT_SIZE` | `PARAMS` | 单字典词条上限 | 5000 | 1000–20000 | `8000` |
| `FILES_PER_FOLDER` | `PARAMS` | 单文件夹内记忆文件数 | 100 | 20–500 | `200` |
| `memory_content_preview` | `MemexA.__init__` | 记忆预览截断长度（字符） | 200 | 50–1000 | `300` |
| `max_working_memories` | `MemexA.__init__` | 工作记忆上限（触发清理） | 50 | 20–200 | `100` |

---

## 四、分布式裂变控制
| 参数名 | 所在行区域 | 作用 | 缺省值 | 安全范围 | 修改示例 |
|--------|------------|------|--------|----------|----------|
| `FISSION_ENABLED` | `PARAMS` | 是否启用裂变 | `True` | `True` / `False` | `False`（关闭裂变） |
| `MAX_SUB_DICTS` | `PARAMS` | 最大子字典数量 | 20 | 5–100 | `10` |
| `FISSION_CHECK_INTERVAL` | `PARAMS` | 每多少次添加触发检查 | 10 | 5–100 | `20` |
| `FISSION_THRESHOLD` | `PARAMS` | 裂变推荐阈值 | 0.8 | 0.5–0.95 | `0.85` |

---

## 五、延迟反馈调节
| 参数名 | 所在行区域 | 作用 | 缺省值 | 安全范围 | 修改示例 |
|--------|------------|------|--------|----------|----------|
| `window_size` | `DELAYED_FEEDBACK` | 对话轮数窗口 | 5 | 3–10 | `7` |
| `AC_HIGH` | `PARAMS` | 高分阈值（百分制） | 80 | 60–95 | `85` |
| `AC_LOW` | `PARAMS` | 低分阈值（百分制） | 50 | 30–70 | `45` |

---

## 六、文本采样与性能
| 参数名 | 所在行区域 | 作用 | 缺省值 | 安全范围 | 修改示例 |
|--------|------------|------|--------|----------|----------|
| `text_sample_limit` | `TOKENIZER_CONFIG` | 分析前截断字符数 | 500 | 100–2000 | `1000` |
| `cache_enabled` | `TOKENIZER_CONFIG` | 是否启用分词缓存 | `True` | `True` / `False` | `False`（调试时关闭） |
| `optimization_interval` | `PERFORMANCE_CONFIG` | 后台优化间隔（秒） | 300 | 60–3600 | `600` |

---

## 七、X层语法符号
| 参数名 | 所在行区域 | 作用 | 缺省值 | 修改示例 |
|--------|------------|------|--------|----------|
| `max_symbols` | `X_LAYER_CONFIG` | X层符号上限 | 20 | `15` |
| `max_guidance_length` | `X_LAYER_CONFIG` | 引导文本最大长度 | 120 | `80` |

---

## 八、快速修改模板（复制粘贴即可）

### 1. 关闭分布式裂变（省电/省存储）
```python
# 在 PARAMS 区域找到：
"FISSION_ENABLED": {"value": True, ...}
# 改为：
"FISSION_ENABLED": {"value": False, ...}
```

### 2. 降低内存/CPU占用（树莓派Zero）
```python
# 三步：
"text_sample_limit": 200,        # 原500 → 200
"MAX_DICT_SIZE": 2000,           # 原5000 → 2000
"optimization_interval": 600,    # 原300 → 600
```

### 3. 接入本地Ollama
```python
# 1. 改配置
AI_INTERFACE_CONFIG = {
    "model_type": "ollama",
    "timeout_seconds": 30,
    "max_tokens": 1000,
    "temperature": 0.7
}

# 2. 在 ExtendedAIInterface.call_ai_model() 里
# 把 "local" 分支注释掉，启用 "ollama" 分支模板（已写好，去掉注释即可）
```

### 4. 调快/调慢参数自适应
```python
# 更激进：窗口变小，阈值降低
"window_size": 3,          # 原5 → 3
"AC_HIGH": 75,             # 原80 → 75
"AC_LOW": 45,              # 原50 → 45

# 更保守：窗口变大，阈值升高
"window_size": 10,         # 原5 → 10
"AC_HIGH": 90,             # 原80 → 90
"AC_LOW": 55,              # 原50 → 55
```

---

## 九、验证修改生效

运行后输入：
```
👤 你：查看系统状态
```
输出中会显示你修改后的参数值，确认已生效。

---

**所有配置都在代码头部，改完保存立刻生效；没有外部配置文件，没有环境变量，没有YAML。源码即配置。**