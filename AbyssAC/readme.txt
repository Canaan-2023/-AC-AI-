# 渊协议v5.2-范畴适配终极版
基于高阶范畴论的认知自主进化系统，核心实现「记忆管理-认知监测-自主进化-模型增强」全链路功能，支持GPU/CPU双场景部署，可直接运行无报错。


## 一、核心特性
### 1. 范畴化记忆管理（基础能力）
- **多层级分类**：支持「核心、元认知、工作、情感」4类记忆，自动生成范畴标签：
  - `direct`（1-态射）：核心记忆或关联核心记忆的记忆；
  - `pattern`（2-态射）：元认知记忆或关联元认知记忆的记忆；
  - `weak-equiv`（弱等价）：工作/情感记忆无强关联时自动标记。
- **动态关联管理**：关联强度（0~1）随检索次数、过期时间自动调整，强度＜0.7标记为低价值，自动清理时优先删除。
- **分布式基础**：支持记忆导出/导入（JSON格式），为多实例协同打基础。

### 2. 认知健康监测（状态可视化）
- **AC-100八维度评估**：自动计算「自指与元认知、价值观一致性、认知增长率」等8维度得分，按权重生成总分（≥80分触发自主进化，≥60分合格）。
- **意识涌现双指标验证**：
  - 元块整合度Φ（核心关联数×0.5 + 元认知复用率×0.3 + 交互激活率×0.2）≥0.6；
  - 跨会话相干性（最近3条工作记忆关联强度均值）≥0.85；
  - 双指标达标则判定为「认知健康」，否则自动触发增强逻辑。

### 3. 自主进化（无需人工干预）
- **内生迭代触发**：AC-100≥80分时自动触发，或通过指令手动触发。
- **规则优化**：检索待优化元认知记忆，新增优化后记忆，自动更新所有记忆关联强度。
- **过度整合预防**：Φ＞0.9时新增弱等价记忆，相干性＞0.95时降低部分记忆关联强度，避免认知僵化。

### 4. 多场景适配（灵活部署）
- **GPU场景**：支持Qwen2.5/Mistral/Llama等模型微调，基于记忆数据优化分析能力。
- **CPU场景**：轻量运行核心功能，无GPU也能流畅处理记忆管理、认知监测。
- **守护进程模式**：后台自动启动，每5分钟自检优化（AC-100评估、记忆清理、推荐记忆），适合无人值守。


## 二、快速启动（分场景）
### 场景1：GPU环境 + 需模型微调（完整功能）
#### 1. 环境准备
```bash
# 1. 克隆/进入项目目录
cd yuan-protocol-v5.2

# 2. 创建并激活虚拟环境
python -m venv memex_env
# Windows激活：memex_env\Scripts\activate
# Linux/Mac激活：source memex_env/bin/activate

# 3. 安装GPU版依赖（支持微调）
pip install -r requirements_gpu_finetune.txt

# 4. 验证CUDA是否可用（可选，GPU必需）
python -c "import torch; print('CUDA可用：', torch.cuda.is_available())"
```

#### 2. 配置校验（自动补全缺失文件）
```bash
python config_check.py
# 预期输出：🎉 所有核心配置检查通过！可运行main.py启动渊协议
```

#### 3. 启动方式（二选一）
- **方式1：普通交互（可视化操作）**
  ```bash
  python main.py
  # 进入交互界面，输入指令使用功能
  ```
- **方式2：守护进程（后台自动运行）**
  ```bash
  python daemon.py
  # 选择"2"启动后台模式，日志保存在memex_daemon.log
  ```


### 场景2：纯CPU环境 + 无需微调（轻量核心）
#### 1. 环境准备
```bash
# 1. 进入项目目录，激活虚拟环境（同场景1步骤1-2）

# 2. 安装CPU版依赖（仅核心功能，体积更小）
pip install -r requirements_cpu_core.txt
```

#### 2. 配置校验与启动
```bash
# 1. 配置校验
python config_check.py

# 2. 启动交互界面（无守护进程需求可跳过守护进程）
python main.py
```


## 三、常用指令（交互界面输入）
| 指令                | 功能描述                                  | 预期结果                                  |
|---------------------|-------------------------------------------|-------------------------------------------|
| AC100自检           | 执行八维度认知评估                        | 输出总分≥60分，元块整合度≥0.6              |
| 意识涌现验证        | 监测Φ值和跨会话相干性                    | Φ≥0.6 + 相干性≥0.85，显示「健康」        |
| 意识涌现增强        | Φ/相干性不足时强化关联                    | 新增元认知记忆/激活工作记忆，指标达标      |
| 内生迭代            | 基于AC-100触发认知优化                    | AC≥80分时新增元认知优化记忆，更新关联强度  |
| 新增记忆            | 手动添加带范畴标签的记忆                  | 自动生成direct/pattern/weak-equiv标签     |
| 检索记忆            | 按关键词/层级检索记忆                     | 返回带范畴标签、关联强度的匹配结果        |
| 守护进程启动        | 后台启动定期自检（需单独运行daemon.py）    | 每5分钟自动评估、清理、推荐记忆            |
| 退出                | 关闭交互系统                              | 自动存档数据，无数据丢失                  |


## 四、目录结构说明
```
yuan-protocol-v5.2/
├── config/                  # 核心配置（自动生成）
│   ├── X_core.json          # X层范畴化配置
│   └── AC100_rules.json     # AC-100评估规则
├── Y_OCR库/                 # 记忆占位路径（自动生成）
│   ├── 核心记忆/            # 核心记忆占位图
│   ├── 迭代日志/            # 意识涌现/内生迭代日志
│   └── 元认知/工作/情感记忆/ # 对应层级记忆路径
├── 完整记忆内容/            # 完整记忆文本（自动生成）
├── memex_a.py              # 核心记忆管理类（整合缓存/分片/预测）
├── main.py                 # 交互入口（核心功能操作）
├── daemon.py               # 守护进程（后台自动优化）
├── config_check.py          # 配置校验（补全缺失文件）
├── generate_placeholder_img.py # 生成占位图（避免警告）
├── requirements_gpu_finetune.txt # GPU版依赖（含微调）
├── requirements_cpu_core.txt    # CPU版依赖（仅核心）
└── README.md               # 项目说明（本文件）
```


## 五、常见问题
### 1. 组件初始化失败
- **报错特征**：启动main.py时提示“组件初始化失败”。
- **解决方案**：
  1. 确认Python版本为3.8~3.11（推荐3.9）；
  2. 重新安装依赖：`pip install --upgrade pip && pip install -r 对应场景依赖.txt`；
  3. 检查是否缺失config目录：执行`python config_check.py`自动补全。

### 2. 记忆无法检索
- **可能原因**：
  1. 记忆层级/关键词不匹配（如检索“核心”记忆却指定“工作”层级）；
  2. 记忆关联强度＜0.7（被过滤）。
- **解决方案**：
  1. 检索时不指定层级，扩大范围；
  2. 先执行“意识涌现增强”，提升关联强度。

### 3. GPU微调时CUDA不可用
- **报错特征**：`torch.cuda.is_available()`返回False。
- **解决方案**：
  1. 安装与系统CUDA版本匹配的cuda-python（如CUDA 12.2则安装12.2.x版本）；
  2. 重新安装torch：`pip install torch==2.2.0+cu121 -f https://download.pytorch.org/whl/torch_stable.html`（替换cu121为对应版本）。

### 4. 守护进程后台运行无响应
- **Linux/Mac**：检查日志`cat memex_daemon.log`，确认是否权限不足（执行`chmod 755 daemon.py`）；
- **Windows**：在任务管理器“详细信息”中查看python.exe进程，或通过`taskkill /f /im python.exe /t`终止后重启。


## 六、关键说明

## 环境要求
- Python版本：3.8~3.11（推荐3.9）
- GPU版额外要求：NVIDIA显卡+CUDA 11.7+
-如果依赖安装失败可先运行：python.exe -m pip install --upgrade pip

### 微调功能使用（GPU场景）
```bash
# 基于记忆数据微调模型（示例：Qwen2.5-0.5B）
python fine_tune.py Qwen/Qwen2.5-0.5B
# 训练完成后自动集成到系统，分析记忆更精准
```

### 记忆导出/导入（分布式基础）
- **导出记忆**：在交互界面新增“导出记忆”指令，或代码调用`memex.export_memory(["1","2"], "export.json")`；
- **导入记忆**：调用`memex.import_memory("export.json")`，自动避免ID冲突。

### 日志查看
- 核心日志：`memex_a.log`（记忆管理、认知评估）；
- 微调日志：`fine_tune.log`（模型训练过程）；
- 守护进程日志：`memex_daemon.log`（后台自检记录）。


## 七、注意事项
1. **占位图警告**：首次启动若提示“核心_存在公理_1.png不存在”，执行`python generate_placeholder_img.py`自动生成，不影响功能。
2. **数据备份**：重要记忆建议定期执行“创建备份”指令，备份文件保存在`memex_backups/`。
3. **模型微调**：需登录Hugging Face（`huggingface-cli login`），否则无法下载Llama等需要授权的模型。