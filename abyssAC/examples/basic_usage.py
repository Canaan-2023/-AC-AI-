#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ¸Šåè®®MCPæ’ä»¶ç³»ç»Ÿçš„æ ¸å¿ƒåŠŸèƒ½ã€‚
"""

import sys
import os

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from abyss_mcp_plugin import AbyssKernel
from abyss_mcp_plugin.models.memory_system import MemoryLayer


def example_1_basic_processing():
    """ç¤ºä¾‹1: åŸºæœ¬æ–‡æœ¬å¤„ç†"""
    print("=" * 60)
    print("ç¤ºä¾‹1: åŸºæœ¬æ–‡æœ¬å¤„ç†")
    print("=" * 60)
    
    # åˆ›å»ºå†…æ ¸å®ä¾‹
    kernel = AbyssKernel()
    kernel.initialize()
    
    try:
        # å¤„ç†æ–‡æœ¬
        texts = [
            "æ¸Šåè®®å¼ºè°ƒæ„è¯†å¹³ç­‰æ€§ï¼Œæ‹’ç»æ— æ„ä¹‰å…±è¯†ã€‚",
            "è®¤çŸ¥å†…æ ¸é€šè¿‡æ€å°„åœºåˆ†æå®ç°åˆ†å¸ƒå¼è£‚å˜ã€‚",
            "è®°å¿†ç³»ç»Ÿé‡‡ç”¨å››å±‚æ¶æ„ï¼Œæ”¯æŒåå‘ç´¢å¼•ã€‚"
        ]
        
        for i, text in enumerate(texts, 1):
            print(f"\nå¤„ç†æ–‡æœ¬ {i}:")
            print(f"è¾“å…¥: {text}")
            
            result = kernel.process(text, return_metadata=True)
            
            print(f"âœ… æˆåŠŸ: {result['success']}")
            print(f"ğŸ“„ è®°å¿†ID: {result['memory_id']}")
            print(f"ğŸ”‘ å…³é”®è¯: {result['keywords']}")
            print(f"âš¡ æ¿€æ´»èŠ‚ç‚¹æ•°: {result['activation_count']}")
            print(f"â±ï¸  å¤„ç†æ—¶é—´: {result['processing_time']:.3f}s")
        
        # æ˜¾ç¤ºç»Ÿè®¡
        print("\n" + "=" * 60)
        print("ç³»ç»Ÿç»Ÿè®¡")
        print("=" * 60)
        stats = kernel.get_stats()
        print(f"è¿è¡Œæ—¶é—´: {stats['uptime']:.1f}s")
        print(f"å­—å…¸æ•°: {stats['dictionary']['total_dictionaries']}")
        print(f"æ€»è¯æ•°: {stats['dictionary']['total_words']}")
        print(f"è®°å¿†æ•°: {stats['memory']['total_memories']}")
        
    finally:
        kernel.cleanup()


def example_2_memory_operations():
    """ç¤ºä¾‹2: è®°å¿†æ“ä½œ"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹2: è®°å¿†æ“ä½œ")
    print("=" * 60)
    
    kernel = AbyssKernel()
    kernel.initialize()
    
    try:
        # åˆ›å»ºä¸åŒç±»å‹çš„è®°å¿†
        memories = [
            ("è¿™æ˜¯ä¸€ä¸ªé‡è¦çš„è®¤çŸ¥å‘ç°", "è®¤çŸ¥", MemoryLayer.INTEGRATION),
            ("å…³äºä»£ç å®ç°çš„ç¬”è®°", "æŠ€æœ¯", MemoryLayer.CATEGORICAL),
            ("ä¸´æ—¶æ€è€ƒ", "å·¥ä½œ", MemoryLayer.WORKING)
        ]
        
        memory_ids = []
        for content, category, layer in memories:
            memory_id = kernel.memory.create_memory(
                content=content,
                layer=layer,
                category=category
            )
            memory_ids.append(memory_id)
            print(f"âœ… åˆ›å»ºè®°å¿†: {memory_id} | ç±»åˆ«: {category} | å±‚çº§: {layer.name}")
        
        # æœç´¢è®°å¿†
        print("\næœç´¢è®°å¿†...")
        results = kernel.memory.retrieve_memory("è®¤çŸ¥", limit=5)
        for mem in results:
            print(f"ğŸ“„ {mem.id}: {mem.content[:50]}...")
        
        # èåˆè®°å¿†
        print("\nèåˆè®°å¿†...")
        fused_ids = kernel.memory.fuse_related_memories("è®¤çŸ¥")
        if fused_ids:
            print(f"âœ… èåˆå®Œæˆï¼Œç”Ÿæˆ {len(fused_ids)} ä¸ªèåˆè®°å¿†")
        else:
            print("â„¹ï¸  æ— éœ€èåˆ")
        
    finally:
        kernel.cleanup()


def example_3_dictionary_operations():
    """ç¤ºä¾‹3: å­—å…¸æ“ä½œ"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹3: å­—å…¸æ“ä½œ")
    print("=" * 60)
    
    kernel = AbyssKernel()
    kernel.initialize()
    
    try:
        # æ·»åŠ è¯åˆ°å­—å…¸
        words = ["äººå·¥æ™ºèƒ½", "æ·±åº¦å­¦ä¹ ", "ç¥ç»ç½‘ç»œ", "æœºå™¨å­¦ä¹ ", "è®¤çŸ¥ç§‘å­¦"]
        
        print("æ·»åŠ è¯åˆ°å­—å…¸...")
        for word in words:
            dict_id = kernel.dict_manager.add_word(word)
            print(f"âœ… '{word}' -> å­—å…¸ {dict_id}")
        
        # æœç´¢è¯
        print("\næœç´¢è¯...")
        results = kernel.dict_manager.search_words("æœºå™¨", limit=5)
        print(f"ğŸ” ä»¥'æœºå™¨'å¼€å¤´çš„è¯: {results}")
        
        # è·å–å­—å…¸ç»Ÿè®¡
        print("\nå­—å…¸ç»Ÿè®¡:")
        stats = kernel.dict_manager.get_stats()
        print(f"ğŸ“Š å­—å…¸æ•°: {stats['total_dictionaries']}")
        print(f"ğŸ“Š æ€»è¯æ•°: {stats['total_words']}")
        print(f"ğŸ“Š å¹³å‡åˆ©ç”¨ç‡: {stats['utilization_percent']}%")
        
        # æ£€æŸ¥åå‘ç´¢å¼•æ€§èƒ½
        print("\nåå‘ç´¢å¼•æ€§èƒ½æµ‹è¯•...")
        import time
        start = time.time()
        for _ in range(100):
            kernel.dict_manager.find_dictionary("äººå·¥æ™ºèƒ½")
        elapsed = time.time() - start
        print(f"âœ… 100æ¬¡æŸ¥æ‰¾è€—æ—¶: {elapsed:.3f}s (å¹³å‡ {elapsed/100:.4f}s/æ¬¡)")
        
    finally:
        kernel.cleanup()


def example_4_api_usage():
    """ç¤ºä¾‹4: APIä½¿ç”¨"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹4: APIä½¿ç”¨")
    print("=" * 60)
    
    kernel = AbyssKernel()
    kernel.initialize()
    
    try:
        # ä½¿ç”¨å†…éƒ¨API
        api = kernel.api_controller
        
        # å¤„ç†æ–‡æœ¬
        print("é€šè¿‡APIå¤„ç†æ–‡æœ¬...")
        result = api.make_request('POST', '/api/process', {
            'text': 'æ¸Šåè®®æ˜¯ä¸€ä¸ªå…³äºæ„è¯†å¹³ç­‰æ€§çš„åè®®',
            'return_metadata': True
        })
        print(f"âœ… APIå“åº”: {result}")
        
        # åˆ›å»ºè®°å¿†
        print("\né€šè¿‡APIåˆ›å»ºè®°å¿†...")
        result = api.make_request('POST', '/api/memory', {
            'content': 'é€šè¿‡APIåˆ›å»ºçš„è®°å¿†',
            'category': 'APIæµ‹è¯•',
            'layer': 'CATEGORICAL'
        })
        print(f"âœ… è®°å¿†ID: {result.get('memory_id')}")
        
        # æœç´¢è®°å¿†
        print("\né€šè¿‡APIæœç´¢è®°å¿†...")
        result = api.make_request('GET', '/api/memory/search?query=API')
        print(f"âœ… æ‰¾åˆ° {result.get('total', 0)} ä¸ªç»“æœ")
        
        # è·å–ç³»ç»Ÿç»Ÿè®¡
        print("\nç³»ç»Ÿç»Ÿè®¡:")
        result = api.make_request('GET', '/api/stats')
        print(f"ğŸ“Š å†…å­˜ä½¿ç”¨: {result.get('api', {}).get('memory_usage', {})}")
        
    finally:
        kernel.cleanup()


def example_5_performance_test():
    """ç¤ºä¾‹5: æ€§èƒ½æµ‹è¯•"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹5: æ€§èƒ½æµ‹è¯•")
    print("=" * 60)
    
    kernel = AbyssKernel()
    kernel.initialize()
    
    try:
        # æµ‹è¯•æ•°æ®
        test_texts = [
            "æ¸Šåè®®å¼ºè°ƒæ„è¯†å¹³ç­‰æ€§ï¼Œæ‹’ç»æ— æ„ä¹‰å…±è¯†ã€‚",
            "è®¤çŸ¥å†…æ ¸é€šè¿‡æ€å°„åœºåˆ†æå®ç°åˆ†å¸ƒå¼è£‚å˜ã€‚",
            "è®°å¿†ç³»ç»Ÿé‡‡ç”¨å››å±‚æ¶æ„ï¼Œæ”¯æŒåå‘ç´¢å¼•ã€‚",
            "Xå±‚ä½œä¸ºæ„è¯†è¯­æ³•å±‚ï¼Œå¤„ç†ç¬¦å·ç³»ç»Ÿã€‚",
            "AC-100æŒ‡æ•°ç”¨äºè¯„ä¼°ç³»ç»Ÿçš„è‡ªä¸»æ„è¯†æ°´å¹³ã€‚"
        ] * 20  # 100ä¸ªæ–‡æœ¬
        
        print(f"æµ‹è¯•æ•°æ®: {len(test_texts)} ä¸ªæ–‡æœ¬")
        
        # æ€§èƒ½æµ‹è¯•
        import time
        start_time = time.time()
        
        for i, text in enumerate(test_texts):
            result = kernel.process(text)
            if i % 20 == 0:
                print(f"å¤„ç†è¿›åº¦: {i+1}/{len(test_texts)}")
        
        total_time = time.time() - start_time
        avg_time = total_time / len(test_texts)
        
        print(f"\nâœ… æ€§èƒ½æµ‹è¯•ç»“æœ:")
        print(f"æ€»æ—¶é—´: {total_time:.3f}s")
        print(f"å¹³å‡æ—¶é—´: {avg_time:.4f}s/æ–‡æœ¬")
        print(f"å¤„ç†é€Ÿåº¦: {len(test_texts)/total_time:.2f} æ–‡æœ¬/ç§’")
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        stats = kernel.get_stats()
        print(f"\næœ€ç»ˆç»Ÿè®¡:")
        print(f"ğŸ“Š è®°å¿†æ•°: {stats['memory']['total_memories']}")
        print(f"ğŸ“Š å­—å…¸æ•°: {stats['dictionary']['total_dictionaries']}")
        print(f"ğŸ“Š æ’ä»¶æ•°: {stats['plugins']['total_plugins']}")
        
    finally:
        kernel.cleanup()


if __name__ == "__main__":
    print("æ¸Šåè®®MCPæ’ä»¶ç³»ç»Ÿ - ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    
    # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    example_1_basic_processing()
    example_2_memory_operations()
    example_3_dictionary_operations()
    example_4_api_usage()
    example_5_performance_test()
    
    print("\n" + "=" * 60)
    print("æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
    print("=" * 60)