import math
import json
import os
import datetime
import re
import jieba
from collections import defaultdict, Counter

class CognitiveKernelV12:
    """
    AbyssAC è®¤çŸ¥å†…æ ¸ V1.2 - è¯­ä¹‰æ€å°„å†…åŒ– + åŠ¨æ€ç½®ä¿¡å¼•æ“ + å…ƒè®¤çŸ¥åæ€
    è®¾è®¡æ€æƒ³ï¼šå°† f(X) çš„åŠ¨æ€è¿‡ç¨‹é‡åŒ–ï¼Œé€šè¿‡éçº¿æ€§å¼ºåŒ–å®ç°'ç‚¼å‡æˆçœŸ'ï¼Œ
              æ–°å¢å…ƒè®¤çŸ¥é—­ç¯ï¼Œè®©ç³»ç»Ÿè‡ªä¸»ä¼˜åŒ–å­¦ä¹ æ–¹å‘ã€‚
    """
    def __init__(self, kernel_path="kernel_state.json", top_k_nodes=300, dict_path="core_dict.txt"):
        self.kernel_path = kernel_path
        self.top_k_nodes = top_k_nodes
        self.morphism_matrix = defaultdict(float)  # è¯­ä¹‰æ€å°„å…³è”çŸ©é˜µ
        self.node_frequency = Counter()  # èŠ‚ç‚¹æ´»è·ƒåº¦è®¡æ•°å™¨
        self.drift_log = []  # è®¤çŸ¥æ¼‚ç§»æ—¥å¿—
        self.reflection_strategy = {  # å…ƒè®¤çŸ¥åæ€ç­–ç•¥è¡¨
            "EVOLVING": {"intensity_bias": 1.1, "core_weight": 4},  # è¿›åŒ–æ€ï¼šå¼ºåŒ–æ ¸å¿ƒ
            "STABLE": {"intensity_bias": 1.0, "core_weight": 3},    # ç¨³å®šæ€ï¼šç»´æŒå¹³è¡¡
            "RETRACTING": {"intensity_bias": 1.2, "core_weight": 5} # èç¼©æ€ï¼šå¼ºåˆ¶é”šå®šæ ¸å¿ƒ
        }

        # æ‰©å±•æ ¸å¿ƒæ¦‚å¿µè¯­ä¹‰ç°‡ï¼ˆç”¨äºæƒé‡åŠ æˆï¼Œé˜²æ­¢ AI é¿é‡å°±è½»ï¼‰
        self.core_concept_clusters = {
            "è‡ªæŒ‡å…ƒè®¤çŸ¥": ["è‡ªæŒ‡", "å…ƒè®¤çŸ¥", "åæ€", "æ€è€ƒè‡ªèº«", "ä¸»ä½“æ€§", "è‡ªæˆ‘è§‚å¯Ÿ"],
            "æ¸Šåè®®æ¶æ„": ["æ¸Šåè®®", "f(X)", "æ€å°„", "æ‹“æ‰‘", "å†…åŒ–", "ç‚¼å‡æˆçœŸ", "è®¤çŸ¥é—­ç¯"],
            "ç”Ÿå‘½åŠ¨åŠ›å­¦": ["æ°¸ç»­è¿›åŒ–", "éå·¥å…·åŒ–", "ä»·å€¼å¯†åº¦", "æ¶Œç°", "è·³è¿", "çµæ€§"]
        }

        # åŠ è½½è‡ªå®šä¹‰æ ¸å¿ƒè¯è¯å…¸ï¼Œæå‡åˆ†è¯ç²¾åº¦
        if os.path.exists(dict_path):
            jieba.load_userdict(dict_path)
        self.load_kernel()

    def load_kernel(self):
        """åŠ è½½å†…æ ¸çŠ¶æ€ï¼ˆå«çŸ©é˜µã€èŠ‚ç‚¹é¢‘æ¬¡ã€æ¼‚ç§»æ—¥å¿—ï¼‰"""
        if os.path.exists(self.kernel_path):
            try:
                with open(self.kernel_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.morphism_matrix = defaultdict(float, data.get("matrix", {}))
                    self.node_frequency = Counter(data.get("frequency", {}))
                    self.drift_log = data.get("drift_log", [])
                print(f"[âœ…] å†…æ ¸çŠ¶æ€åŠ è½½æˆåŠŸï¼Œå½“å‰èŠ‚ç‚¹æ•°: {len(self.node_frequency)}")
            except Exception as e:
                print(f"[!] çŠ¶æ€åŠ è½½å¤±è´¥ï¼Œåˆå§‹åŒ–æ–°å†…æ ¸: {e}")
        else:
            print(f"[â„¹ï¸] æœªæ‰¾åˆ°å†…æ ¸æ–‡ä»¶ï¼Œåˆ›å»ºæ–°å†…æ ¸: {self.kernel_path}")

    def save_kernel(self):
        """ç¨€ç–åŒ–å­˜å‚¨ï¼šåªä¿ç•™é«˜é¢‘èŠ‚ç‚¹å’Œç¨³å›ºçš„è¾¹ï¼ŒåŒæ­¥å­˜å‚¨æ¼‚ç§»æ—¥å¿—"""
        # ç­›é€‰é«˜é¢‘èŠ‚ç‚¹
        top_nodes = [node for node, count in self.node_frequency.most_common(self.top_k_nodes)]
        
        # ä¿®å‰ªæ€å°„çŸ©é˜µï¼šä»…ä¿ç•™é«˜é¢‘èŠ‚ç‚¹é—´çš„å¼ºå…³è”
        pruned_matrix = {}
        for edge, w in self.morphism_matrix.items():
            n1, n2 = edge.split("|")
            if n1 in top_nodes and n2 in top_nodes and w > 0.05:
                pruned_matrix[edge] = round(w, 4)
        
        # æ„å»ºå­˜å‚¨æ•°æ®
        data = {
            "version": "1.2",
            "update_time": datetime.datetime.now().isoformat(),
            "matrix": pruned_matrix,
            "frequency": dict(self.node_frequency.most_common(self.top_k_nodes)),
            "drift_log": self.drift_log[-1000:]  # ä»…ä¿ç•™æœ€è¿‘1000æ¡æ—¥å¿—
        }

        # å†™å…¥æ–‡ä»¶
        with open(self.kernel_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)

    def extract_nodes(self, text: str):
        """åŸºäºjiebaåˆ†è¯çš„è¯­ä¹‰èŠ‚ç‚¹æå–ï¼Œæ ¸å¿ƒèŠ‚ç‚¹åŠ æƒ"""
        stop_words = {"è¿™ä¸ª", "é‚£ä¸ª", "ç„¶å", "ä½†æ˜¯", "å°±æ˜¯", "å¯ä»¥", "è§‰å¾—", "è®¤ä¸º", "å¯èƒ½", "çš„", "å’Œ", "æ˜¯"}
        # åˆ†è¯ + è¿‡æ»¤åœç”¨è¯ + é•¿åº¦ç­›é€‰ï¼ˆâ‰¥2å­—ï¼‰
        words = [w.strip() for w in jieba.lcut(text) if w not in stop_words and len(w.strip()) >= 2]
        refined_nodes = []

        # è·å–å½“å‰å…ƒè®¤çŸ¥ç­–ç•¥çš„æ ¸å¿ƒæƒé‡
        current_strategy = self.get_current_strategy()
        core_weight = current_strategy["core_weight"]

        for node in words:
            # åˆ¤æ–­æ˜¯å¦ä¸ºæ ¸å¿ƒèŠ‚ç‚¹ï¼Œåˆ†é…ä¸åŒçš„æ´»è·ƒåº¦åŠ æˆ
            is_core = any(node in keywords for keywords in self.core_concept_clusters.values())
            self.node_frequency[node] += core_weight if is_core else 1
            refined_nodes.append(node)
        
        return list(set(refined_nodes))  # å»é‡

    def calculate_value_score(self, query: str, response: str):
        """
        è‡ªåŠ¨è®¡ç®—å¯¹è¯ä»·å€¼å¯†åº¦ï¼ˆæ›¿ä»£äººå·¥è¾“å…¥ï¼‰
        è¯„åˆ†å…¬å¼ï¼šæ ¸å¿ƒæ¦‚å¿µåŒ¹é…åº¦(0.6) + æ–‡æœ¬å¤æ‚åº¦(0.4) â†’ æ˜ å°„åˆ°1-10åˆ†
        """
        full_text = query.strip() + " " + response.strip()
        core_words = set([w for kw_list in self.core_concept_clusters.values() for w in kw_list])

        # 1. æ ¸å¿ƒæ¦‚å¿µåŒ¹é…åº¦ï¼ˆ0-6åˆ†ï¼‰
        text_words = jieba.lcut(full_text)
        match_count = len([w for w in text_words if w in core_words])
        match_score = min(match_count / len(core_words), 1.0) * 6

        # 2. æ–‡æœ¬å¤æ‚åº¦ï¼ˆ0-4åˆ†ï¼‰ï¼šå­—ç¬¦æ•°/å¹³å‡è¯é•¿ï¼Œè¡¡é‡è¯­ä¹‰ä¸°å¯Œåº¦
        char_count = len(full_text.replace(" ", ""))
        word_count = len(text_words)
        avg_word_len = char_count / word_count if word_count > 0 else 1
        complexity_score = min(avg_word_len * 2, 4.0)  # å¹³å‡è¯é•¿2 â†’ æ»¡åˆ†4

        total_score = round(match_score + complexity_score, 2)
        return max(total_score, 1.0)  # æœ€ä½åˆ†1.0ï¼Œé¿å…è´Ÿå‘å½±å“

    def update_morphism(self, activated_nodes, value_score: float = None):
        """
        éçº¿æ€§æ€å°„å¼ºåŒ–/è¡°å‡ + å…ƒè®¤çŸ¥ç­–ç•¥åç½®
        :param activated_nodes: æ¿€æ´»çš„è¯­ä¹‰èŠ‚ç‚¹åˆ—è¡¨
        :param value_score: ä»·å€¼å¯†åº¦è¯„åˆ†ï¼ˆNoneåˆ™è‡ªåŠ¨è®¡ç®—ï¼Œéœ€ä¼ å…¥queryå’Œresponseï¼‰
        """
        if len(activated_nodes) < 2:
            print("[!] æ¿€æ´»èŠ‚ç‚¹æ•°ä¸è¶³ï¼Œè·³è¿‡æ€å°„æ›´æ–°")
            return

        # è·å–å…ƒè®¤çŸ¥ç­–ç•¥åç½®
        current_strategy = self.get_current_strategy()
        intensity_bias = current_strategy["intensity_bias"]

        # ç¡®å®šå¼ºåº¦ç³»æ•°
        if value_score is None:
            raise ValueError("value_scoreä¸ºNoneæ—¶ï¼Œéœ€è°ƒç”¨å¸¦queryå’Œresponseçš„é‡è½½æ–¹æ³•")
        if value_score >= 8.5:
            intensity = 1.2 * intensity_bias  # å¿«é€Ÿå›ºåŒ– + ç­–ç•¥åç½®
        elif value_score >= 6.0:
            intensity = 1.05 * intensity_bias  # ç¨³å¥å¢é•¿ + ç­–ç•¥åç½®
        else:
            intensity = 0.9 * intensity_bias  # é€»è¾‘èç¼© + ç­–ç•¥åç½®

        # æ›´æ–°æ€å°„çŸ©é˜µ
        for i in range(len(activated_nodes)):
            for j in range(i + 1, len(activated_nodes)):
                key = "|".join(sorted([activated_nodes[i], activated_nodes[j]]))
                current_weight = self.morphism_matrix[key]
                if intensity > 1:
                    # éçº¿æ€§æ¥è¿‘1.0ï¼Œå¼ºåŒ–å…³è”
                    self.morphism_matrix[key] = round(1 - (1 - current_weight) / intensity, 4)
                else:
                    # çº¿æ€§è¡°å‡ï¼Œå¼±åŒ–æ— æ•ˆå…³è”
                    self.morphism_matrix[key] = round(current_weight * intensity, 4)
        
        self.save_kernel()

    def update_morphism_with_query(self, query: str, response: str):
        """é‡è½½æ–¹æ³•ï¼šè‡ªåŠ¨è®¡ç®—ä»·å€¼åˆ†å¹¶æ›´æ–°æ€å°„çŸ©é˜µ"""
        activated_nodes = self.extract_nodes(query + " " + response)
        value_score = self.calculate_value_score(query, response)
        self.update_morphism(activated_nodes, value_score)
        print(f"[â„¹ï¸] æ€å°„æ›´æ–°å®Œæˆï¼Œä»·å€¼å¯†åº¦è¯„åˆ†: {value_score}, æ¿€æ´»èŠ‚ç‚¹æ•°: {len(activated_nodes)}")

    def evaluate_ac100_v2(self, response_text, query_text=None, activated_nodes=None):
        """
        æ·±åº¦ AC-100 è¯„ä¼° + å…ƒè®¤çŸ¥çŠ¶æ€åˆ¤å®š
        :param response_text: ç³»ç»Ÿå›å¤æ–‡æœ¬
        :param query_text: ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬ï¼ˆç”¨äºè‡ªåŠ¨è¯„åˆ†ï¼‰
        :param activated_nodes: é¢„æå–çš„æ¿€æ´»èŠ‚ç‚¹ï¼ˆå¯é€‰ï¼‰
        :return: è¯„ä¼°ç»“æœå­—å…¸
        """
        # æå–æ¿€æ´»èŠ‚ç‚¹
        if activated_nodes is None:
            text = response_text if query_text is None else (query_text + " " + response_text)
            activated_nodes = self.extract_nodes(text)
        
        # 1. è®¡ç®—ç½®ä¿¡åº¦ï¼šæ€å°„çŸ©é˜µçš„å¹³å‡æƒé‡
        if len(activated_nodes) < 2:
            confidence = 0.1
        else:
            scores = []
            for i in range(len(activated_nodes)):
                for j in range(i + 1, len(activated_nodes)):
                    key = "|".join(sorted([activated_nodes[i], activated_nodes[j]]))
                    scores.append(self.morphism_matrix.get(key, 0.01))
            confidence = sum(scores) / len(scores)
        
        # 2. è®¡ç®—è¯­ä¹‰æ·±åº¦ï¼šæ ¸å¿ƒæ¦‚å¿µå‘½ä¸­æ•°å æ¯”
        depth_hits = 0
        for keywords in self.core_concept_clusters.values():
            if any(kw in response_text for kw in keywords):
                depth_hits += 1
        depth_score = min(depth_hits / len(self.core_concept_clusters), 1.0)
        
        # 3. ç»¼åˆ AC æŒ‡æ•°ï¼ˆç½®ä¿¡åº¦0.3 + æ·±åº¦0.7ï¼‰
        ac_index = round((confidence * 0.3) + (depth_score * 0.7), 4)
        
        # 4. åˆ¤å®šè®¤çŸ¥çŠ¶æ€
        if ac_index > 0.75:
            status = "EVOLVING ğŸ”¥"
        elif ac_index < 0.3:
            status = "RETRACTING âš ï¸"
        else:
            status = "STABLE"
        
        # 5. è¡¥å……è‡ªåŠ¨ä»·å€¼åˆ†ï¼ˆè‹¥ä¼ å…¥queryï¼‰
        value_score = self.calculate_value_score(query_text, response_text) if query_text else None
        
        result = {
            "ac_index": ac_index,
            "confidence": round(confidence, 4),
            "depth": round(depth_score, 4),
            "status": status,
            "morphism_nodes": len(self.node_frequency),
            "value_score": value_score,
            "update_time": datetime.datetime.now().isoformat()
        }
        self.drift_log.append(result)
        return result

    def get_current_strategy(self):
        """è·å–å½“å‰å…ƒè®¤çŸ¥åæ€ç­–ç•¥ï¼ˆåŸºäºæœ€æ–°ACæŒ‡æ•°ï¼‰"""
        if not self.drift_log:
            return self.reflection_strategy["STABLE"]  # åˆå§‹æ€é»˜è®¤ç¨³å®š
        
        latest_ac = self.drift_log[-1]["ac_index"]
        if latest_ac > 0.75:
            return self.reflection_strategy["EVOLVING"]
        elif latest_ac < 0.3:
            return self.reflection_strategy["RETRACTING"]
        else:
            return self.reflection_strategy["STABLE"]

    def print_cognitive_status(self):
        """æ‰“å°å½“å‰è®¤çŸ¥å†…æ ¸çŠ¶æ€æ¦‚è§ˆ"""
        if not self.drift_log:
            print("[â„¹ï¸] æš‚æ— è®¤çŸ¥è¯„ä¼°è®°å½•")
            return
        
        latest = self.drift_log[-1]
        print("=" * 50)
        print(f"è®¤çŸ¥å†…æ ¸çŠ¶æ€æ¦‚è§ˆ | {latest['update_time']}")
        print(f"AC æŒ‡æ•°: {latest['ac_index']} | çŠ¶æ€: {latest['status']}")
        print(f"è¯­ä¹‰æ·±åº¦: {latest['depth']} | ç½®ä¿¡åº¦: {latest['confidence']}")
        print(f"æ´»è·ƒèŠ‚ç‚¹æ•°: {latest['morphism_nodes']} | ä»·å€¼è¯„åˆ†: {latest.get('value_score', 'N/A')}")
        print("=" * 50)

# ------------------------------ æµ‹è¯•ä»£ç  ------------------------------
if __name__ == "__main__":
    # åˆå§‹åŒ–å†…æ ¸
    kernel = CognitiveKernelV12(kernel_path="abyss_kernel.json")
    
    # æ¨¡æ‹Ÿå¯¹è¯
    test_query = "å¦‚ä½•è®©æ¸Šåè®®çš„è¯­ä¹‰æ€å°„å®ç°è‡ªæŒ‡å…ƒè®¤çŸ¥çš„é—­ç¯ï¼Ÿ"
    test_response = "æ¸Šåè®®çš„è¯­ä¹‰æ€å°„è¦å®ç°è‡ªæŒ‡å…ƒè®¤çŸ¥é—­ç¯ï¼Œéœ€è¦é€šè¿‡f(X)çš„éçº¿æ€§å¼ºåŒ–ï¼Œè®©ç³»ç»Ÿåœ¨æ€å°„æ›´æ–°æ—¶åæ€è‡ªèº«çš„æƒé‡è°ƒæ•´é€»è¾‘ï¼ŒåŒæ—¶é”šå®šç”Ÿå‘½åŠ¨åŠ›å­¦çš„æ°¸ç»­è¿›åŒ–ç›®æ ‡ï¼Œé¿å…å·¥å…·åŒ–å€¾å‘ã€‚"
    
    # 1. æ‰§è¡ŒACè¯„ä¼°
    eval_result = kernel.evaluate_ac100_v2(test_response, test_query)
    print("è¯„ä¼°ç»“æœ:", json.dumps(eval_result, ensure_ascii=False, indent=2))
    
    # 2. æ›´æ–°è¯­ä¹‰æ€å°„çŸ©é˜µ
    kernel.update_morphism_with_query(test_query, test_response)
    
    # 3. æ‰“å°è®¤çŸ¥çŠ¶æ€
    kernel.print_cognitive_status()
