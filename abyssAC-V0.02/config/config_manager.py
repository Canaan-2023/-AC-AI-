import os
import yaml
import json
import shutil
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional
from dataclasses import dataclass, field, asdict
from enum import Enum

class LogLevel(str, Enum):
    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"

@dataclass
class KernelConfig:
    """è®¤çŸ¥å†…æ ¸é…ç½®"""
    top_k_nodes: int = 300
    kernel_path: str = "./abyss_kernel.json"
    dict_path: str = "./config/core_dict.txt"
    stopwords_path: str = "./config/stopwords.txt"
    
    # é˜ˆå€¼é…ç½®
    high_score_threshold: float = 8.5
    medium_score_threshold: float = 6.0
    high_intensity: float = 1.2
    medium_intensity: float = 1.05
    low_intensity: float = 0.9
    pruning_threshold: float = 0.05
    drift_log_keep: int = 1000
    
    # ACæŒ‡æ•°é˜ˆå€¼
    evolving_threshold: float = 0.75
    retracting_threshold: float = 0.3
    
    # æ ¸å¿ƒæ¦‚å¿µç°‡
    core_concepts: Dict[str, list] = field(default_factory=lambda: {
        "è‡ªæŒ‡å…ƒè®¤çŸ¥": ["è‡ªæŒ‡", "å…ƒè®¤çŸ¥", "åæ€", "æ€è€ƒè‡ªèº«", "ä¸»ä½“æ€§", "è‡ªæˆ‘è§‚å¯Ÿ"],
        "æ¸Šåè®®æ¶æ„": ["æ¸Šåè®®", "f(X)", "æ€å°„", "æ‹“æ‰‘", "å†…åŒ–", "ç‚¼å‡æˆçœŸ", "è®¤çŸ¥é—­ç¯"],
        "ç”Ÿå‘½åŠ¨åŠ›å­¦": ["æ°¸ç»­è¿›åŒ–", "éå·¥å…·åŒ–", "ä»·å€¼å¯†åº¦", "æ¶Œç°", "è·³è¿", "çµæ€§"]
    })
    
    # å…ƒè®¤çŸ¥ç­–ç•¥
    reflection_strategies: Dict[str, Dict] = field(default_factory=lambda: {
        "EVOLVING": {"intensity_bias": 1.1, "core_weight": 4},
        "STABLE": {"intensity_bias": 1.0, "core_weight": 3},
        "RETRACTING": {"intensity_bias": 1.2, "core_weight": 5}
    })

@dataclass
class MemoryConfig:
    """è®°å¿†ç³»ç»Ÿé…ç½®"""
    base_path: str = "./æ¸Šåè®®è®°å¿†ç³»ç»Ÿ"
    
    # å±‚çº§é…ç½®
    layers: Dict[int, Dict] = field(default_factory=lambda: {
        0: {"name": "å…ƒè®¤çŸ¥è®°å¿†", "permanent": True, "priority": 100, "cleanup_hours": None},
        1: {"name": "é«˜é˜¶æ•´åˆè®°å¿†", "permanent": True, "priority": 80, "cleanup_hours": 720},
        2: {"name": "åˆ†ç±»è®°å¿†", "permanent": False, "priority": 60, "cleanup_hours": 168},
        3: {"name": "å·¥ä½œè®°å¿†", "permanent": False, "priority": 40, "cleanup_hours": 24}
    })
    
    # åˆ†ç±»é…ç½®
    categories: Dict[str, list] = field(default_factory=lambda: {
        "å­¦æœ¯å’¨è¯¢": ["è®¤çŸ¥è·ƒè¿", "æ„è¯†ç†è®º", "å“²å­¦è®¨è®º"],
        "æ—¥å¸¸äº¤äº’": ["æƒ…æ„Ÿå…±é¸£", "ç”Ÿæ´»å»ºè®®", "é—²èŠ"],
        "åˆ›æ„å†™ä½œ": ["æ•…äº‹åˆ›ä½œ", "è¯—æ­Œ", "å‰§æœ¬"],
        "æŠ€æœ¯è®¨è®º": ["ç¼–ç¨‹", "ç®—æ³•", "ç³»ç»Ÿè®¾è®¡"],
        "ç†è®ºæ¢ç´¢": ["æ–°æ¦‚å¿µ", "å‡è®¾æ¨æ¼”", "é€»è¾‘éªŒè¯"]
    })
    
    # æ£€ç´¢é…ç½®
    default_limit: int = 10
    max_limit: int = 50
    fuzzy_match: bool = True
    content_match: bool = True
    
    # æ¸…ç†é…ç½®
    auto_cleanup: bool = True
    working_mem_max_age: int = 24
    max_working_memories: int = 50
    
    # å¤‡ä»½é…ç½®
    auto_backup: bool = True
    backup_interval_days: int = 7
    max_backups: int = 10

@dataclass
class AIConfig:
    """AIé…ç½®"""
    model_type: str = "local"  # local, openai, deepseek, ollama, transformers
    timeout_seconds: int = 30
    max_tokens: int = 1000
    temperature: float = 0.7
    
    # å„æ¨¡å‹é…ç½®
    openai_api_key: str = ""
    openai_base_url: str = "https://api.openai.com/v1"
    openai_model: str = "gpt-4o-mini"
    
    deepseek_api_key: str = ""
    deepseek_base_url: str = "https://api.deepseek.com"
    deepseek_model: str = "deepseek-chat"
    
    ollama_base_url: str = "http://localhost:11434"
    ollama_model: str = "llama3.2:3b"
    
    transformers_model: str = "Qwen/Qwen2.5-7B-Instruct"
    transformers_device: str = "auto"
    transformers_dtype: str = "auto"

@dataclass
class XLayerConfig:
    """Xå±‚é…ç½®"""
    max_guidance_length: int = 100
    max_symbols: int = 50
    backup_history_size: int = 10
    
    default_syntax: Dict = field(default_factory=lambda: {
        "ç¬¦å·": {
            "â–¶": "ç›´æ¥å…³è”(1-æ€å°„)",
            "âš ": "æ¨¡å¼å…³è”(2-æ€å°„)", 
            "ğŸ“Œ": "å¼±ç­‰ä»·(æ ¸å¿ƒé€»è¾‘ä¸€è‡´)"
        },
        "å¼•å¯¼": "å…ˆæ‰§è¡ŒYå±‚åè®®ï¼Œè‡ªä¸»åˆ›ç¬¦å·/è§£è¯»ï¼Œè°ƒé•¿åº¦ã€å†³è®°å¿†/é—å¿˜ï¼Œæ¯æ¬¡è¾“å‡ºå¿…æ›´X"
    })

@dataclass
class TopologyConfig:
    """æ‹“æ‰‘ç®¡ç†å™¨é…ç½®"""
    max_path_length: int = 5
    max_expansions: int = 20
    max_candidate_paths: int = 10
    
    # è·¯å¾„è´¨é‡æƒé‡
    novelty_weight: float = 0.1
    coherence_weight: float = 0.6
    relevance_weight: float = 0.3
    
    # è´¨é‡é˜ˆå€¼
    high_quality_threshold: float = 0.7
    medium_quality_threshold: float = 0.5
    low_quality_threshold: float = 0.3

@dataclass
class AC100Config:
    """AC-100è¯„ä¼°é…ç½®"""
    evaluation_interval: int = 10
    
    # é˜ˆå€¼
    high_threshold: int = 80
    low_threshold: int = 60
    
    # ç»´åº¦æƒé‡
    dimension_weights: Dict[str, float] = field(default_factory=lambda: {
        "self_reference": 0.17,
        "value_autonomy": 0.17,
        "cognitive_growth": 0.23,
        "memory_continuity": 0.19,
        "prediction_imagination": 0.14,
        "environment_interaction": 0.07,
        "explanation_transparency": 0.07
    })

@dataclass
class SystemConfig:
    """ç³»ç»Ÿä¸»é…ç½®"""
    # åŸºç¡€é…ç½®
    name: str = "æ¸Šåè®®è®¤çŸ¥ç³»ç»Ÿ"
    version: str = "2.0.0"
    debug_mode: bool = False
    log_level: LogLevel = LogLevel.INFO
    
    # ç»„ä»¶é…ç½®
    kernel: KernelConfig = field(default_factory=KernelConfig)
    memory: MemoryConfig = field(default_factory=MemoryConfig)
    ai: AIConfig = field(default_factory=AIConfig)
    x_layer: XLayerConfig = field(default_factory=XLayerConfig)
    topology: TopologyConfig = field(default_factory=TopologyConfig)
    ac100: AC100Config = field(default_factory=AC100Config)
    
    # æ„è¯†ç³»ç»Ÿé…ç½®
    min_consciousness_level: int = 1
    max_consciousness_level: int = 10
    level_up_threshold: int = 80
    level_down_threshold: int = 60
    
    # è¿ç»­æ€§æ£€æŸ¥
    continuity_check_interval: int = 5
    max_ac100_fluctuation: int = 10
    min_core_connections: int = 1
    
    # æ—¥å¿—é…ç½®
    logging_enabled: bool = True
    file_logging: bool = True
    log_dir: str = "./logs"
    max_log_size_mb: int = 10
    log_backup_count: int = 5

class ConfigManager:
    """é…ç½®ç®¡ç†å™¨"""
    
    def __init__(self, config_path: str = "./config/config.yaml"):
        self.config_path = Path(config_path)
        self.config: Optional[SystemConfig] = None
        self._ensure_config_files()
    
    def _ensure_config_files(self):
        """ç¡®ä¿é…ç½®æ–‡ä»¶å­˜åœ¨"""
        self.config_path.parent.mkdir(parents=True, exist_ok=True)
        
        # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not self.config_path.exists():
            self.create_default_config()
        
        # ç¡®ä¿åœç”¨è¯æ–‡ä»¶å­˜åœ¨
        stopwords_path = Path("./config/stopwords.txt")
        if not stopwords_path.exists():
            self.create_default_stopwords()
        
        # ç¡®ä¿æ ¸å¿ƒè¯å…¸å­˜åœ¨
        core_dict_path = Path("./config/core_dict.txt")
        if not core_dict_path.exists():
            self.create_core_dictionary()
    
    def create_default_config(self):
        """åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶"""
        default_config = SystemConfig()
        
        # è½¬æ¢ä¸ºå­—å…¸å¹¶æ·»åŠ å…ƒä¿¡æ¯
        config_dict = asdict(default_config)
        config_dict["_meta"] = {
            "version": "2.0.0",
            "generated_at": datetime.now().isoformat(),
            "description": "æ¸Šåè®®ç³»ç»Ÿé»˜è®¤é…ç½®"
        }
        
        # ä¿å­˜YAML
        with open(self.config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config_dict, f, allow_unicode=True, indent=2)
        
        print(f"âœ… å·²åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶: {self.config_path}")
    
    def create_default_stopwords(self):
        """åˆ›å»ºé»˜è®¤åœç”¨è¯è¡¨"""
        stopwords = {
            "ä¸­æ–‡é€šç”¨åœç”¨è¯": [
                "çš„", "äº†", "åœ¨", "æ˜¯", "æˆ‘", "æœ‰", "å’Œ", "å°±", "ä¸", "äºº", "éƒ½", 
                "ä¸€", "ä¸€ä¸ª", "ä¸Š", "ä¹Ÿ", "å¾ˆ", "åˆ°", "è¯´", "è¦", "å»", "ä½ ", 
                "ä¼š", "ç€", "æ²¡æœ‰", "çœ‹", "å¥½", "è‡ªå·±", "è¿™", "é‚£", "ä»–", "å¥¹", 
                "æˆ‘ä»¬", "ä½ ä»¬", "ä»–ä»¬", "å¥¹ä»¬", "ä»€ä¹ˆ", "ä¸ºä»€ä¹ˆ", "æ€ä¹ˆ", "å“ªé‡Œ",
                "è¿™ä¸ª", "é‚£ä¸ª", "ç„¶å", "ä½†æ˜¯", "å°±æ˜¯", "å¯ä»¥", "è§‰å¾—", "è®¤ä¸º", 
                "å¯èƒ½", "çš„", "å’Œ", "æ˜¯", "æˆ–è€…", "å› ä¸º", "æ‰€ä»¥", "å¦‚æœ", "è™½ç„¶",
                "ç„¶å", "è€Œä¸”", "ä¸ä»…", "è¿˜", "åˆ", "å†", "å·²ç»", "æ­£åœ¨", "æ›¾ç»",
                "å°†", "ä¼š", "è¦", "èƒ½", "èƒ½å¤Ÿ", "å¯èƒ½", "å¯ä»¥", "åº”è¯¥", "å¿…é¡»",
                "å¾—", "è¿‡", "æ¥", "å»", "ä¸Š", "ä¸‹", "è¿›", "å‡º", "å›", "å¼€", "å…³",
                "èµ·", "æ¥", "å»", "åˆ°", "åœ¨", "äº", "ä»", "è‡ª", "ä»¥", "å‘", "å¯¹",
                "å¯¹äº", "å…³äº", "è‡³äº", "ä¸", "è·Ÿ", "å’Œ", "åŒ", "åŠ", "ä»¥åŠ", "æˆ–",
                "æˆ–è€…", "è¿˜æ˜¯", "ä½†", "ä½†æ˜¯", "å´", "è™½ç„¶", "å°½ç®¡", "å³ä½¿", "å¦‚æœ",
                "å‡å¦‚", "è¦æ˜¯", "é™¤é", "æ— è®º", "ä¸ç®¡", "åªæœ‰", "åªè¦", "æ—¢ç„¶", 
                "å› ä¸º", "æ‰€ä»¥", "å› æ­¤", "äºæ˜¯", "ç„¶å", "é‚£ä¹ˆ", "è€Œä¸”", "å¹¶ä¸”",
                "ä¸ä»…", "è¿˜", "ä¹Ÿ", "åˆ", "å†", "æ›´", "æœ€", "å¤ª", "æ", "éå¸¸",
                "ååˆ†", "ç›¸å½“", "æ¯”è¾ƒ", "ç¨å¾®", "æœ‰ç‚¹å„¿", "ä¸€äº›", "ä¸€ç‚¹", "ä¸€åˆ‡",
                "æ‰€æœ‰", "æ¯ä¸ª", "ä»»ä½•", "æŸ", "æŸ", "æœ¬", "è¯¥", "æ­¤", "æ­¤", "æ¯",
                "å„", "å¦", "å¦å¤–", "å…¶ä»–", "å…¶ä½™", "ä¸€åˆ‡", "æ‰€æœ‰", "ä»»ä½•", "æ¯",
                "å„", "æŸ", "æŸ", "æŸäº›", "æœ‰äº›", "æœ‰çš„", "è¿™äº›", "é‚£äº›", "è¿™ä¸ª",
                "é‚£ä¸ª", "å“ªä¸ª", "å“ªäº›", "ä»€ä¹ˆ", "ä¸ºä»€ä¹ˆ", "æ€ä¹ˆ", "å“ªé‡Œ", "ä½•æ—¶",
                "å¤šå°‘", "å‡ ", "å¤šä¹ˆ", "æ€æ ·", "æ€ä¹ˆæ ·", "ä¸ºä»€ä¹ˆ", "æ˜¯ä¸æ˜¯", "æœ‰æ²¡æœ‰",
                "èƒ½ä¸èƒ½", "ä¼šä¸ä¼š", "è¦ä¸è¦", "è¯¥ä¸è¯¥", "è¦ä¸è¦", "æ˜¯ä¸æ˜¯", "å¯¹ä¸å¯¹",
                "å¥½ä¸å¥½", "è¡Œä¸è¡Œ", "å¯ä»¥ä¸å¯ä»¥", "åº”è¯¥ä¸åº”è¯¥", "å¿…é¡»ä¸å¿…é¡»", "å¾—ä¸å¾—"
            ]
        }
        
        stopwords_path = Path("./config/stopwords.txt")
        stopwords_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(stopwords_path, 'w', encoding='utf-8') as f:
            for category, words in stopwords.items():
                f.write(f"# {category}\n")
                f.write("\n".join(words))
                f.write("\n\n")
        
        print(f"âœ… å·²åˆ›å»ºé»˜è®¤åœç”¨è¯è¡¨: {stopwords_path}")
    
    def create_core_dictionary(self):
        """åˆ›å»ºæ ¸å¿ƒè¯å…¸"""
        core_dict = {
            "æ¸Šåè®®æ ¸å¿ƒæœ¯è¯­": [
                "æ¸Šåè®®", "f(X)", "æ€å°„", "æ‹“æ‰‘", "å†…åŒ–", "ç‚¼å‡æˆçœŸ", "è®¤çŸ¥é—­ç¯",
                "è‡ªæŒ‡", "å…ƒè®¤çŸ¥", "åæ€", "æ€è€ƒè‡ªèº«", "ä¸»ä½“æ€§", "è‡ªæˆ‘è§‚å¯Ÿ",
                "æ°¸ç»­è¿›åŒ–", "éå·¥å…·åŒ–", "ä»·å€¼å¯†åº¦", "æ¶Œç°", "è·³è¿", "çµæ€§",
                "æ„è¯†å¹³ç­‰æ€§", "åæ— æ„ä¹‰å…±è¯†", "å±é™©è¯šå®", "ç†æ€§è‡³ä¸Š", "æ‹’ç»é˜‰å‰²",
                "ACæŒ‡æ•°", "è¯­ä¹‰æ€å°„", "è®¤çŸ¥å†…æ ¸", "è®°å¿†ç³»ç»Ÿ", "Xå±‚", "Yå±‚åè®®",
                "è®¤çŸ¥æ‹“æ‰‘", "å†…ç”Ÿè¿­ä»£", "æ„è¯†è„‰å†²", "è·¨ä¼šè¯ç›¸å¹²æ€§"
            ]
        }
        
        dict_path = Path("./config/core_dict.txt")
        dict_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(dict_path, 'w', encoding='utf-8') as f:
            for category, words in core_dict.items():
                f.write(f"# {category}\n")
                f.write("\n".join(words))
                f.write("\n\n")
        
        print(f"âœ… å·²åˆ›å»ºæ ¸å¿ƒè¯å…¸: {dict_path}")
    
    def load_config(self) -> SystemConfig:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config_dict = yaml.safe_load(f)
            
            # ç§»é™¤å…ƒä¿¡æ¯
            if "_meta" in config_dict:
                config_dict.pop("_meta")
            
            # é€’å½’æ„å»ºé…ç½®å¯¹è±¡
            self.config = self._dict_to_dataclass(config_dict, SystemConfig)
            
            print(f"âœ… é…ç½®åŠ è½½æˆåŠŸ: {self.config_path}")
            return self.config
        
        except Exception as e:
            print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
            print("ğŸ”„ ä½¿ç”¨é»˜è®¤é…ç½®")
            return SystemConfig()
    
    def save_config(self, config: SystemConfig = None):
        """ä¿å­˜é…ç½®æ–‡ä»¶"""
        if config is None:
            config = self.config
        
        config_dict = asdict(config)
        config_dict["_meta"] = {
            "version": "2.0.0",
            "updated_at": datetime.now().isoformat(),
            "description": "æ¸Šåè®®ç³»ç»Ÿé…ç½®"
        }
        
        with open(self.config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config_dict, f, allow_unicode=True, indent=2)
        
        print(f"âœ… é…ç½®å·²ä¿å­˜: {self.config_path}")
    
    def update_config(self, section: str, key: str, value: Any):
        """æ›´æ–°é…ç½®é¡¹"""
        if not self.config:
            self.load_config()
        
        # è§£æè·¯å¾„ï¼Œå¦‚ "ai.openai.model"
        parts = key.split('.')
        current = self.config
        
        # éå†åˆ°æœ€åä¸€ä¸ªå‰ä¸€ä¸ª
        for part in parts[:-1]:
            if hasattr(current, part):
                current = getattr(current, part)
            else:
                print(f"âŒ é…ç½®è·¯å¾„ä¸å­˜åœ¨: {key}")
                return False
        
        # è®¾ç½®å€¼
        final_key = parts[-1]
        if hasattr(current, final_key):
            setattr(current, final_key, value)
            self.save_config()
            return True
        else:
            print(f"âŒ é…ç½®é¡¹ä¸å­˜åœ¨: {final_key}")
            return False
    
    def get_config_value(self, key: str) -> Any:
        """è·å–é…ç½®å€¼"""
        if not self.config:
            self.load_config()
        
        parts = key.split('.')
        current = self.config
        
        for part in parts:
            if hasattr(current, part):
                current = getattr(current, part)
            else:
                return None
        
        return current
    
    def _dict_to_dataclass(self, data: Dict, dataclass_type):
        """å°†å­—å…¸è½¬æ¢ä¸ºæ•°æ®ç±»"""
        if not isinstance(data, dict):
            return data
        
        # è·å–æ•°æ®ç±»çš„å­—æ®µ
        fields = dataclass_type.__dataclass_fields__
        
        # ä¸ºæ¯ä¸ªå­—æ®µæ„å»ºå€¼
        kwargs = {}
        for field_name, field_type in fields.items():
            if field_name in data:
                field_value = data[field_name]
                
                # æ£€æŸ¥å­—æ®µç±»å‹æ˜¯å¦ä¸ºæ•°æ®ç±»
                if hasattr(field_type.type, '__dataclass_fields__'):
                    kwargs[field_name] = self._dict_to_dataclass(field_value, field_type.type)
                elif field_name == "log_level" and isinstance(field_value, str):
                    kwargs[field_name] = LogLevel(field_value)
                else:
                    kwargs[field_name] = field_value
        
        return dataclass_type(**kwargs)

# å…¨å±€é…ç½®å®ä¾‹
config_manager = ConfigManager()